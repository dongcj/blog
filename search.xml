<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2Fm%2FParted%E3%80%81kpartx%E3%80%81losetup%E3%80%81sfdisk%E3%80%81e2fsck%E3%80%81resize2fs%E5%88%86%E5%8C%BA%E6%89%A9%E7%9B%98%2F</url>
    <content type="text"><![CDATA[1. linux 根分区修改为 lvm First Create an LVM partition: 123pvcreate /dev/sdb1vgcreate vg01 /dev/sdb1lvcreate -L 100%VG -n lv01 vg01 Format this new LVM partition with ext3 or ext4 1mkfs.ext4 /dev/vg01/lv01 Create a new mount point and then mount the LVM Partition on it 12mkdir /mnt/NEW_ROOT_PARTITIONmount /dev/vg01/lv01 /mnt/NEW_ROOT_PARTITION Copy all contents of “/” to the newly mounted folder 12tar -cvpf - --one-file-system --acls --xattrs --selinux / | tar -C /mnt/NEW_ROOT_PARTITION -xcp -aux /dev /mnt/NEW_ROOT_PARTITION edit the file – /mnt/NEW_ROOT_PARTITION/etc/fstab to reflect the new root 1/dev/vg01/lv01 / ext4 defaults 1 1 chroot to new filesystem and create initrd with raid and lvm support 1234mount --bind /dev /mnt/NEW_ROOT_PARTITION/devchroot /mnt/NEW_ROOT_PARTITIONmount -t proc /proc /procmount -t sysfs /sys /sys 12vgscanvgchange -ay 1234umount /sysumount /procexitmv /mnt/lv0/boot/initrd-`uname -r`.lvm.img /boot Edit /boot/grub/grub.conf to point to new root /dev/vg_new_root/lv0 12update-grubgrub-set-default Reboot 1reboot 2. 虚拟机增加系统盘根分区大小 注意：镜像如果是 qcow2 格式，请先转换为 raw 格式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 此方法适用于分区后连接的空间 , 如果是 swap, 将其删除，并在最末尾建 swap )# 先增加实例文件大小，例如可以使用 dd 命令 dd if=/dev/zero of=/tmp/temp_expand bs=1M count=4096（增加 4 GB）cat /tmp/temp_expand &gt;&gt;/var/lib/libvirt/images/my_vm.img# 或者使用 qemu-img 命令进行大小调整 qemu-img resize my_vm.img +100G# 挂载文件至系统，以便找出是否有 swap devicekpartx -a -p p /var/lib/libvirt/images/my_vm.img# 刷新下分区 partprobe /dev/loop0# If has swap device, del the swap deviceswapDevice=`sfdisk -s -l /dev/loop0 | grep -e 'Linux swap' |awk '&#123;print $1&#125;'`# Del swapparted -s $&#123;loop&#125; rm $&#123;swap_part_num&#125;# If does't have, add the new swap deviceparted -s /dev/loop1 "unit mb mkpart primary linux-swap -2048MB -0"# 或者先只划分空间，再用 mkswap 进行操作 # 可选的：mkswap -v1 /dev/mapper/loop1p3# 重新刷新新增加的 swap 设备 kpartx -d -p p /var/lib/libvirt/images/my_vm.imgkpartx -a -p p /var/lib/libvirt/images/my_vm.img# 将新的 lo 设备分区进行打印 sfdisk -d /dev/loop0 &gt;/tmp/sfdisk_dump# 如果有 swap 分区，则 root 分区为 (root start), (swap start - root start)；如果没有 , 则为"(root start),"new_root="401625,14227239" # (样例, 根据实际情况修改)converted_root_device=`echo "/dev/loop0p1" | sed -e 's/\//\\\\\//g'`sed -e "s/^$&#123;converted_root_device&#125;.*$/$new_root/" /tmp/sfdisk_dump | sfdisk --no-reread --force /dev/loop0# FS resizee2fsck -pv /dev/mapper/loop0p1resize2fs -f /dev/mapper/loop0p1# umount 分区 kpartx -d -p p /var/lib/libvirt/images/my_vm.imglosetup -d /dev/loop0 3. parted 使用 12345678910111213# 4. create all 100% space to one part$ parted -s /dev/sdb mklabel gpt# 5. -a means "align mode"$ parted -a optimal -s /dev/sdb "mkpart image-disk 0% 100%"# 6. create other partparted -a optimal -s /dev/sdb "mkpart logical 59G 459G"parted -a optimal -s /dev/sdb "mkpart logical 459G 859G"# 7. remove partparted -s /dev/sdb rm 2parted -s /dev/sdb rm 3 4. 分区对齐 12345678910111213$ cat /sys/block/sdb/queue/optimal_io_size 1048576$ cat /sys/block/sdb/queue/minimum_io_size 262144$ cat /sys/block/sdb/alignment_offset 0$ cat /sys/block/sdb/queue/physical_block_size 512$ mkpart primary 2048s 100%(parted) align-check optimal 1 1 aligned 5. Linux dd 备份文件后还原 5.1. 使用 parted 分区 如上 5.2. Copy /boot/grub 及 rootfs 将已备份好的数据复制过来 5.3. 安装 Grub 引导 1grub-install --root-directory=/mnt/ /dev/sda 注意： --root-directory=/mnt/ 一定需要带上！]]></content>
  </entry>
  <entry>
    <title><![CDATA[修改 Npm 安装源为国内源]]></title>
    <url>%2Fm%2F%E4%BF%AE%E6%94%B9npm%E5%AE%89%E8%A3%85%E6%BA%90%E4%B8%BA%E5%9B%BD%E5%86%85%E6%BA%90%2F</url>
    <content type="text"><![CDATA[淘宝源地址：http://npm.taobao.org/ 删除已有 npm 包 (可选) 12345# 查看已安装的 npm packagenpm -g ls ## 删除所有 npmnpm ls -gp | awk -F/ '/node_modules/ &amp;&amp; !/node_modules.*node_modules/ &#123;print $NF&#125;' | xargs npm -g rm npm ls -g 如果报错，可以进行以下处理 : 12345678# （原因是 node-modules 中不允许用软链接，但 inherits 却用了）：npm ERR! missing: inherits@*, required by undefined@undefinednpm ERR! missing: inherits@*, required by block-stream@0.0.7npm ERR! missing: inherits@*, required by fstream@0.1.24cd /usr/lib/node_modules/unlink inheritmv inherits@2/ inherits/ 12345npm update npm -g set registry=https://registry.npm.taobao.orgnpm config set ca ""npm install npm -g set registry=https://registry.npm.taobao.orgnpm config delete ca 或者做个 cnpm 的 alias 12345678910111213141516171819# install cnpmnpm install -g cnpm --registry=https://registry.npm.taobao.org# make aliasalias cnpm="npm --registry=https://registry.npm.taobao.org \--cache=$HOME/.npm/.cache/cnpm \--disturl=https://npm.taobao.org/dist \--userconfig=$HOME/.cnpmrc"# Or alias it in .bashrc or .zshrcecho '\n#alias for cnpm\nalias cnpm="npm --registry=https://registry.npm.taobao.org \ --cache=$HOME/.npm/.cache/cnpm \ --disturl=https://npm.taobao.org/dist \ --userconfig=$HOME/.cnpmrc"' &gt;&gt; ~/.zshrc &amp;&amp; source ~/.zshrc# install module / sync / infocnpm install &lt;NAME&gt;cnpm sync connectcnpm info connect]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fm%2F%E5%B8%B8%E7%94%A8%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[1. 常用工具 1.1. Basic 12345678910111213141516171819202122232425262728293031# Process ps auxef # 分组显示 %CPU %MEM 及 START_TIMEps -eLf # 打印线程pstree -al[pha] [PID] # 查看某进程的详细情况pwdx # 查看某进程的启动目录# Loadtop | uptime | sar -q 2 10# CPUsar -u [-P 0] 2 10 mpstat [-P 0] 2 10# Memsar -r 2 10 vmstat 2 10free vmtouchlsmem# Diskiostat -m 2 10sar -d 2 10 # FS Inodesar -F 2 10sar -v 2 10# Swapsar -W 2 10 ps 字段说明 可以用 ps -a -uroot -o pid,ppid,stat,command 根据 Flag 来判断 1234567891011121314151617181920212223242526272829303132F(Flag)：一系列数字的和，表示进程的当前状态。这些数字的含义为： 00：若单独显示，表示此进程已被终止。 01：进程是核心进程的一部分，常驻于系统主存。如： sched、 vhand 、bdflush 等。 02：Parent is tracing process. 04 ：Tracing parent&apos;s signal has stopped the process; the parent is waiting (ptrace(S)). 10：进程在优先级低于或等于 25 时，进入休眠状态，而且不能用信号唤醒，例如在等待一个 inode 被创建时 20：进程被装入主存（primary memory） 40：进程被锁在主存，在事务完成前不能被置换 e S(state of? the process) O：进程正在处理器运行 ms 这个状态从来木见过， 倒是 R 常见 S：休眠状态（sleeping） R：等待运行（runable） R Running or runnable (on run queue) 进程处于运行或就绪状态I：空闲状态（idle） Z：僵尸状态（zombie） T：跟踪状态（Traced） B：进程正在等待更多的内存页 D: 不可中断的深度睡眠，一般由 IO 引起，同步 IO 在做读或写操作时，cpu 不能做其它事情，只能等待，这时进程处于这种状态，如果程序采用异步 IO，这种状态应该就很少见到了C(cpu usage)：cpu 利用率的估算值&lt;high-priority (not nice to other users)N low-priority (nice to other users)L has pages locked into memory (for real-time and custom IO)s is a session leaderl is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)+ is in the foreground process group# 2. 清除 ZOMBIE（僵尸）进程可以使用如下方法：1&gt; kill – 18 PPID （PPID 是其父进程） 这个信号是告诉父进程，该子进程已经死亡了，请收回分配给他的资源。2 &gt; 如果不行则看能否终止其父进程（如果其父进程不需要的话）。先看其父进程又无其他子进程，如果有，可能需要先 kill 其他子进程，也就是兄弟进程。方法是：kill – 15 PID1 PID2(PID1,PID2 是僵尸进程的父进程的其它子进程)。然后再 kill 父进程：kill – 15 PPID 这样僵尸进程就可能被完全杀掉了。 free 字段说明 12345$ freetotal used free shared buffers cachedMem: 255268 238332 16936 0 85540 126384-/+ buffers/cache: 26408 228860 free2：未被使用的 buffers 与 cache 和未被分配的内存之和，这就是系统当前实际可用内存。 total1 = used1 + free1 total1 = used2 + free2 used1 = buffers1 + cached1 + used2 free2 = buffers1 + cached1 + free1 buffer: 缓冲区 缓冲区，一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。通过缓冲区，可以使进程之间的相互等待变少，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。 cache: 高速缓存 高速缓存，是位于 CPU 与主内存间的一种容量较小但速度很高的存储器。由于 CPU 的速度远高于主内存，CPU 直接从内存中存取数据要等待一定时间周期，Cache 中保存着 CPU 刚用过或循环使用的一部分数据，当 CPU 再次使用该部分数据时可从 Cache 中直接调用 , 这样就减少了 CPU 的等待时间 , 提高了系统的效率。Cache 又分为一级 Cache(L1 Cache) 和二级 Cache(L2 Cache)，L1 Cache 集成在 CPU 内部，L2 Cache 早期一般是焊在主板上 , 现在也都集成在 CPU 内部，常见的容量有 256KB 或 512KB L2 Cache。 总的来说： buffer : 作为 buffer cache 的内存，是块设备的读写缓冲区； cache: 作为 page cache 的内存 , 文件系统的 cache 1.2. xtop 12345678910111213141516# System monitoring dashboard for terminal，见图片htop | gtop # iotop iotop -Pao -d 2 # 实时显示不中断iotop -b -o -t -k -q -n2 # 显示二次进程占用 io 最高的进程# 见图片atop rtop # 远程通过 ssh 查看其它服务器的信息vtop # node.js 的 console 查看服务器状态ctop # Containers monitoring toolitop # monitors /proc/interrupts gtop screenshot gtop screenshot atop screenshot atop screenshot 2. 网络监测工具 2.1. 带宽及使用 12345678910111213141516171819202122232425262728293031323334# iperf 服务端 : iperf [-u] -s # iperf 客户端 : iperf [-u] -c IP_ADDR_OF_SERVER -f M -t 60 -P 30 -b 100M# (-u UDP 测试 ; -f 单位 , 可以是 kmKM; -t 测试时间 ; -P 线程数 ; -b 测试数据包大小)# 用来测试网络性能工具Netperf# 查看 上 / 下 行速率及高级网卡参数，有一个基本的图bmon # ifstat(仅限 Ubuntu)ifstat# 可以看到每个主机连接的包及大小iptraf-ng# 简单直观的查看上 / 下 行速度bwm-ng# iftop，可以看到每个主机连接 和 一段时间总的使用量# `-B` 设置 Byte 为单位，默认是 bit； -F Filter，表示只看这个段iftop# yet another network load monitor# 和 bmon 类似slurm # 不太准确，偏高nethogs# ntopng# web-based network traffic monitoring application 2.2. 数据包分析 123456789101112131415# tcpdumptcpdump 'port 5901 and (host 192.168.109.1)'# ngrep ngrep -qd any -W byline . tcp dst port 2003 ## any 匹配所有接口，. 匹配所有内容 目标端口为 2003 的包ngrep -qd any -W byline "^(GET|POST)" port not 22# conntrackconntrack -L | head -n 20# 抓取网络数据包，详细分析wiresharktshark tcptrace 2.3. 路由 DNS 诊断 1234567# trace 工具dig | traceroute | mtr | nslookup# 常用法dig +trace @8.8.8.8 www.baidu.comdig +tcp @8.8.8.8 www.baidu.comdig +short @8.8.8.8 www.baidu.com 2.4. 网络连接状态 2.4.1. netstat 12345678910# 1. 查看所有的连接数netstat -n | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'# 2. 查看指定端口连接数netstat -n | grep :22 | awk '/^tcp/&#123;++S[$NF]&#125; END &#123;for (key in S) print key,S[key]&#125;'# 3. 查看指定端口 + 指定状态(ESTABLISHED)regex="10[0-2][0-9]"netstat -anp | egrep $regex | grep -E "tcp.*ESTABLISHED" | awk '&#123;print $4, $5&#125;' | \ cut -d: -f2 | sort -u 2.4.2. proc 1cat /proc/net/sockstat 2.4.3. ss(sockets statics) 12345# use ss(the same as 1, but more faster and detail)ss -ant | awk 'NR&gt;1 &#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;'# ESTABLISHED order by "Recv-Q &amp; Send-Q"ss -A inet -a | grep -Ev "UNCONN|LISTEN|127.0.0.1" | sort -rk5 | sort -rk3,4 2.4.4. lsof (一切皆文件) 123456789101112131415161718lsof -iTCP -sTCP:ESTABLISHED # tcp/udp 网络服务lsof -i :22 # 知道 22 端口现在运行什么程序lsof -c abc # 显示 abc 进程现在打开的文件# 4. 看进程号为 12 的进程打开了哪些文件等同于 pmap 12 和 netstat -p 12lsof -p 12 # 5. 列出所有的 socket, 等同于 ss -llsof -U # 6. 查看文件被哪个进程打开lsof | grep FILEorDir# 这个等同于使用 /proc/*/mountinfo, 使用下面这个方法可能更优grep -l FILEorDir /proc/*/mountinfo# 7. 找出已删除但还占用空间的文件lsof | grep deleted | grep "filename-of-my-big-file" 解释 1234567891011CLOSED：无连接是活动的或正在进行LISTEN：服务器在等待进入呼叫SYN_RECV：一个连接请求已经到达，等待确认SYN_SENT：应用已经开始，打开一个连接ESTABLISHED：正常数据传输状态FIN_WAIT1：应用说它已经完成FIN_WAIT2：另一边已同意释放ITMED_WAIT：等待所有分组死掉CLOSING：两边同时尝试关闭TIME_WAIT：另一边已初始化一个释放LAST_ACK：等待所有分组死掉 3. 综合工具 3.1. sar (System Activity Reporter) https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/sar.html 1apt install sysstat 追溯过去的统计数据（默认） 周期性的查看当前数据 3.2. ’x’stat 123456vmstat # 综合工具 （通常使用 vmstat -w -S MB 2 50 注：每秒显示 2 次，共显示 50 次）dstat # 综合工具 （通常使用 dstat -cmdnlpsy 注：显示所有）pidstat # 打印进程信息 (Report statistics for Linux tasks, 有占用信息)cifsiostat # 查看 windows 共享的 io 状况mpstat # 查看多处理器状况 （通常使用 mpstat -P ALL 5 2 注：对所有 CPU，每次花费 5 秒收集 5 个，共收集 2 次的）iostat # 监视 I/O 子系统 （通常使用 iostat -xmz 2） vmstat 字段说明 123456789101112131415161718192021222324Procs（进程）:r: 运行队列中进程数量b: 等待 IO 的进程数量Memory（内存）:swpd: 使用虚拟内存大小free: 可用内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小Swap:si: 每秒从交换区写到内存的大小so: 每秒写入交换区的内存大小IO：（现在的 Linux 版本块的大小为 1024bytes）bi: 每秒读取的块数bo: 每秒写入的块数system：in: 每秒中断数，包括时钟中断cs: 每秒上下文切换数CPU（以百分比表示）us: 用户进程执行时间 (user time)sy: 系统进程执行时间 (system time)id: 空闲时间 (包括 IO 等待时间)wa: 等待 IO 时间 iostat 字段说明 12345678910-C 显示 CPU 使用情况-d 显示磁盘使用情况-k 以 KB 为单位显示-m 以 M 为单位显示-N 显示磁盘阵列 (LVM) 信息-n 显示 NFS 使用情况-p[磁盘] 显示磁盘和分区的情况-t 显示终端和 CPU 的信息-x 显示详细信息-V 显示版本信息 3.3. netdata 3.4. nmon 12# mon，每 5 秒记录一次，共记录 100 次并存储文件，然后使用 `nmon analyzer` 进行分析 nmon -F OnlyForTest -s 5 -c 100 3.5. sysdig 点击此处查看 sysdig 用法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 网络sysdig -c topprocs_net # 查看网络带宽占用最多的进程sysdig -c fdcount_by fd.sport "evt.type=accept" # 查看连接最多的服务端口sysdig -c fdcount_by fd.cip "evt.type=accept" # 查看客户端连接最多的 IP_ADDR_OF_SERVERsysdig -p "%proc.name %fd.name" "evt.type=accept and proc.name != httpd" # 列出不是访问 apache 服务的访问连接# IOsysdig -c topprocs_file # 查看使用硬盘带宽最多的进程sysdig -c fdcount_by proc.name "fd.type=file" # 列出使用大量文件描述符的进程sysdig -c fdbytes_by fd.directory "fd.type=file" # 读写磁盘最多的目录sysdig -c fdbytes_by fd.filename "fd.directory=/tmp/" # /tmp 中读写最多的文件sysdig -c fdbytes_by fd.type # 动态根据 FD 的类型显示 I/Osysdig -A -c echo_fds "fd.filename=passwd" # 动态跟踪所有名为 passwd 的文件的 I/Osysdig -c topfiles_bytes # 读写字节最多的文件sysdig -c topfiles_bytes proc.name=httpd # 读写字节最多的 APACHE 文件sysdig -p "%12user.name %6proc.pid %12proc.name %3fd.num %fd.typechar %fd.name" evt.type=open # 侦测文件被打开sysdig -c topprocs_cpu # 观察 CPU 占用最高的进程sysdig -c topprocs_cpu evt.cpu=0 # 观察 CPU0 的最高占用sysdig -s4096 -A -c stdout proc.name=nginx # 观察 cat 进程的输出sysdig -c topfiles_timesysdig -c topfiles_time proc.name=httpdsysdig -c topprocs_errorssysdig -c topfiles_errorssysdig fd.type=file and evt.failed=truesysdig "proc.name=httpd and evt.type=open and evt.failed=true"sysdig -c topscalls_timesysdig -c topscalls "evt.failed=true"sysdig -p "%12user.name %6proc.pid %12proc.name %3fd.num %fd.typechar %fd.name" evt.type=open and evt.failed=truesysdig -c fileslower 1# 安全sysdig -p"%evt.arg.path" "evt.type=chdir and user.name=root"sysdig -A -c echo_fds fd.name=/dev/ptmx and proc.name=sshdsysdig evt.type=open and fd.name contains /etcsysdig -r file.scap -c list_login_shells tarsysdig -r trace.scap.gz -c spy_users proc.loginshellid=5459# 容器sysdig -vcontainers # 容器列表及资源使用情况sysdig -pc # 容器上下文列表sysdig -pc -c topprocs_cpu container.name=wordpress # 查看 wordpress 容器 CPU 占用率最高的进程sysdig -pc -c topprocs_net container.name=wordpress # 查看 wordpress 容器 net 占用率最高的进程sysdig -pc -c topconns container.name=wordpress # 查看 wordpress 容器 net 连接的排名情况sysdig -pc -c topfiles_bytes container.name=wordpress # 查看 wordpress 容器 I/O 字节最多的文件sysdig -pc -c spy_users container.name=wordpress # 查看 wordpress 容器所有命令的执行情况# 应用sysdig -s2000 -X -c echo_fds fd.cip=192.168.1.20 # 显示主机 192.168.1.20 的网络传输数据sysdig -s 2000 -A -c echo_fds fd.port=80 and evt.buffer contains GET # 查看机器所有的 HTTP 请求sysdig -s 2000 -A -c echo_fds evt.buffer contains SELECT # 查看机器所有的 SQL 查询sysdig -s 2000 -A -c echo_fds fd.sip=192.168.30.5 and \ proc.name=apache2 and evt.buffer contains SELECT # 查看来自 APACHE 的 SQL 查询 3.6. bcc BPF (Berkeley Packet Filters)，BCC：BPF Compiler Collection https://github.com/iovisor/bcc 3.7. glances 123456# serverglances -s -B 0.0.0.0 glances server is running on 10.0.2.15:61209# clientglances – c 10.0.2.15 4. 硬件传感器温度 4.1. lm_sensor 1234apt-get -y install lm-sensorssensors-detect --autoservice kmod startsensors 4.2. ipmitool 1ipmitool sensor 5. 其它监测工具 1234567891011121314151617181920212223242526272829gnome-system-monitor/conky # gnome 的 GUI 任务管理器工具jvmtop.sh/jconsole PID # java 占用情况 / 图形界面的 java console 占用情况（很清晰，建议使用）pmap PID # 查看进程打开的文件 , 等同于 lsof -p PID# 硬件信息lshw/lspci/lscpu/lsusb# you can found class using `lshw -short` or `lshw -businfo`lshw -class [system | bus | cpu | storage/disk/volume | memory | network | bridge (pic devices) | display | input ]# ipc 信息lsipc/lsns/# 共享内存ipcs -mipcrm -m &lt;SHMID&gt;# Strace 跟踪进程中的系统调用strace -e open ls # 查看命令 ls 打开的库文件strace -r php worker.php # 查看 worker.php 的 tracestrace -p &lt;PID&gt; # 查看正在运行的进程的 trace# ltrace 查看用户空间ltrace /bin/ls # 运行 /bin/ls 命令，查看这个命令具体调用哪些库# blktraceblktrace -d /dev/sda # 生成块设备的跟踪中信息，需要先 mount -t debugfs none /sys/kernel/debug, 再 blkparse 教程：使用 blktrace 统计磁盘块 I/O 访问频率 6. Linux 监控脚本 12345678910111213141516171819202122232425262728#!/bin/bashDAT="`date +%Y%m%d`"HOUR="`date +%H`"DIR="/var/log/mon/host_$&#123;DAT&#125;/$&#123;HOUR&#125;"DELAY=60COUNT=60# whether the responsible directory existmkdir -p $&#123;DIR&#125;# general checkexport TERM=linux/usr/bin/top -b -d $&#123;DELAY&#125; -n $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/top_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;# cpu check/usr/bin/sar -u $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/cpu_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;#/usr/bin/mpstat -P 0 $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/cpu_0_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;#/usr/bin/mpstat -P 1 $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/cpu_1_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;# memory check/usr/bin/vmstat $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/vmstat_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;# I/O check/usr/bin/iostat $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/iostat_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;# network check/usr/bin/sar -n DEV $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/net_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;#/usr/bin/sar -n EDEV $&#123;DELAY&#125; $&#123;COUNT&#125; &gt; $&#123;DIR&#125;/net_edev_$&#123;DAT&#125;.log 2&gt;&amp;1 &amp;]]></content>
  </entry>
  <entry>
    <title><![CDATA[SSH_config_proxycommand]]></title>
    <url>%2Fm%2FSSH_config_proxycommand%2F</url>
    <content type="text"><![CDATA[1. ProxyCommand 12345678# 直接跳到远程计算机 ssh -o "ProxyCommand ssh -p 1098 lmx@proxy.machine nc -w 1 %h %p" -p 1098 lmx@target.machine# 拷贝文件到远程计算机 scp -o "ProxyCommand ssh -p 1098 lmx@proxy.machine nc -w 1 %h %p" -P 1098 -r lmx@target.machine:~/rdsAgent .# 在远程计算机执行命令 ssh -o "ProxyCommand ssh -p 1098 lmx@proxy.machine nc -w 1 %h %p" -p 1098 lmx@target.machine 'ip a' 2. ssh config file example 123456789101112131415$ cat ~/.ssh/configHost *ForwardAgent yesForwardX11 noKeepAlive yesServerAliveInterval 30CheckHostIP noControlMaster autoControlPath /tmp/ssh_mux_%h_%p_%r# client --&gt; 203.195.207.108:46707 --&gt; 118.193.254.66:22Host hk-jumpserverUser rootIdentityFile /cygdrive/c/Users/root/id_rsaProxyCommand ssh -i /cygdrive/c/Users/root/id_rsa root@203.195.207.108 -p 46707 nc 118.193.254.66 22]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fm%2FDocker%E5%AE%89%E8%A3%85%E5%8F%8A%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[弱网环境为了支持 bbr、aufs，建议安装 linux-image-extra 内核, 参考：Linux 升级 kernel 及 tcp_BBR 1. 准备步骤 1.1. 关闭 apparmor（可选） 123# 如果有些需要特权应用，需要关闭systemctl stop apparmorsystemctl disable apparmor 1.2. 服务器时间同步 如果不配置时间同步，可能会导致调度服务有可能不正常 , 建议使用 UTC 时间 建议使用 timedatectl 来进行时间设置 123# 直接删除 /etc/localtime 即可使用 UTC 时间daterm -rf /etc/localtime 1.3. 支持 BBR，请升级内核至 4.9 以上版本（弱网环境建议） 如果要支持 aufs，请安装 linux-image-extra 的包 参考链接： Linux 升级 Kernel 及 tcp_BBR 1.4. 服务器 IP 设置 参考：常用命令 -&gt; Ubuntu IP 配置 1.5. 设置 hostname 12echo "&lt;HOSTNAME&gt;" &gt;/etc/hostname &amp;&amp; hostname &lt;HOSTNAME&gt;hostnamectl set-hostname svi1r01n08 2. 安装 2.1. Ubuntu 安装 2.1.1. 方法一：下载 离线包 安装（推荐） 12wget https://download.docker.com/linux/ubuntu/dists/yakkety/pool/stable/amd64/docker-ce_17.03.2~ce-0~ubuntu-yakkety_amd64.debapt install -y ./docker-ce_17.03.2~ce-0~ubuntu-yakkety_amd64.deb 2.1.2. 方法二：使用 脚本安装 安装 123# clone 后直接脚本安装 , CentOS 没有测试过git clone https://github.com/rancher/install-docker.gitcd ./install-docker 2.1.3. 方法三：使用 apt 安装 新版 1234567891011121314apt-get updateapt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -add-apt-repository \ "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable" 2.1.4. 方法四：使用 apt 安装 旧版 1234567891011# if you want install pre version# add the repo to the aptdeb [arch=amd64] https://download.docker.com/linux/ubuntu zesty stabledeb-src [arch=amd64] https://download.docker.com/linux/ubuntu zesty stable# show the version avaiableapt updateapt-cache madison docker-ce# install the specify docker releaseapt install docker-ce=17.06.2~ce-0~ubuntu 2.2. CentOS 安装 2.2.1. 方法一：下载 离线包 安装（推荐） 123wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.03.2.ce-1.el7.centos.x86_64.rpmwget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch.rpmyum install -y ./docker-ce*.rpm 2.2.2. 方法二：yuｍ 在线安装 12345678910111213141516171819202122yum install -y yum-utils \ device-mapper-persistent-data \ lvm2yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo# optionalyum-config-manager --enable docker-ce-edgeyum-config-manager --enable docker-ce-testyum-config-manager --disable docker-ce-edge# show yum list docker-ce --showduplicates | sort -r# install the versionyum install docker-ce-&lt;VERSION STRING&gt;# startsystemctl enable dockersystemctl start docker 3. 使用证书认证 123456# 以下二种方法均可cat ~/certs/domain.crt &gt;&gt;/etc/pki/tls/certs/ca-bundle.crtsystemctl restart dockercp ~/certs/domain.crt /etc/docker/certs.d/151.106.8.135/ca.crtsystemctl restart docker 4. 配置加速及代理 4.1. Docker 加速器（用于国内加速，可选） 以下操作需 重启 Docker 服务生效 vi /etc/docker/daemon.json 12345678&#123; "registry-mirrors": [ "https://2lqq34jg.mirror.aliyuncs.com", "https://pee6w651.mirror.aliyuncs.com", "https://registry.docker-cn.com", "http://hub-mirror.c.163.com" ]&#125; 4.2. 配置 Docker 代理（国内无法访问国外某些网站的 https，可选） 4.2.1. 临时使用 123# 代理环境中直接启动 dockerdPROXY_ADDR=192.168.1.227:1080http_proxy=$PROXY_ADDR https_proxy=$PROXY_ADDR dockerd 4.2.2. 永久生效 可以通过在 systemd 方式加入代理配置文件 12mkdir -p /etc/systemd/system/docker.service.dvi /etc/systemd/system/docker.service.d/proxy.conf proxy.conf 内容如下： 123[Service]Environment=&quot;HTTP_PROXY=http://pc.dongcj.com:1080&quot; \ &quot;HTTPS_PROXY=http://pc.dongcj.com:1080&quot; &quot;NO_PROXY=localhost,127.0.0.1,192.168.10.23&quot; 12345systemctl daemon-reloadsystemctl show --property=Environment docker# restart dockersystemctl restart docker 5. 安装 docker-compose、docker-machine 5.1. docker-compose（可选） 123456789101112131415# docker-compose VERSION:# https://github.com/docker/compose/releases# get the latest infoDOCKER_COMPOSE_ARCH=docker-compose-Linuxcurl -s https://api.github.com/repos/docker/compose/releases/latest | \ jq -r ".assets[] | select(.name | test(\"$&#123;DOCKER_COMPOSE_ARCH&#125;\")) | .browser_download_url"# download the latest versiondockerComposeVersion=1.22.0curl -L https://github.com/docker/compose/releases/download/$dockerComposeVersion/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --version 5.2. docker-machine（可选） 1234567891011121314curl -L https://github.com/docker/machine/releases/download/v0.9.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machinechmod +x /tmp/docker-machinecp /tmp/docker-machine /usr/local/bin/docker-machine# 使用 docker-machine(支持 virtualbox、阿里云等)# 所有的 Available driver plugins：&gt; https://github.com/docker/docker.github.io/blob/master/machine/AVAILABLE_DRIVER_PLUGINS.md# create aws machinedocker-machine create --driver amazonec2 --amazonec2-access-key AKI******* \ --amazonec2-secret-key 8T93C******* aws-sandbox# 直接使用本地服务器docker-machine create --driver none --url=tcp://192.168.1.112:2376 svi1r01n02 6. Docker 常用配置 判断是否有网络 root 权限 12345678910111213if ip link add dummy0 type dummy 2&gt;&amp;1 | grep -q "not permitted"; thencat 1&gt;&amp;2 &lt;&lt;'EOF'Error: This Docker image must be run in privileged mode.For detailed instructions, please visit:https://github.com/hwdsl2/docker-ipsec-vpn-serverEOF exit 1fiip link delete dummy0 &gt;/dev/null 2&gt;&amp;1 6.1. 使用自定义参数启动 docker vi /lib/systemd/system/docker.service 1ExecStart=/usr/bin/dockerd $DOCKER_NETWORK_OPTIONS $DOCKER_OPTS $DOCKER_DNS_OPTIONS 类似和配置代理一样，也可以直接配置 docker 选项配置到下面文件中 vi /lib/systemd/system/docker.service.d/docker-options.conf 12345678# --graph 指定了 docker 家目录的位置# -b=br0 指定用 br0 为桥接# 以下选项根据需要选择性的使用，不需要所有都加上Environment="DOCKER_OPTS=--insecure-registry=10.254.0.0/16 --graph=/opt/docker \ --registry-mirror=http://b438f72b.m.daocloud.io --iptables=false \ --storage-driver=aufs --tls=true --selinux-enabled -b=br0 \ --tlscert=/var/docker/server.pem --tlskey=/var/docker/serverkey.pem \ -H tcp://192.168.1.112:2376 --exec-driver=lxc" 6.2. Docker 直接使用外部块存储 映射为 container 内部盘，可以自定义使用 read、write、mknode 操作 12docker run --device=/dev/sdc:/dev/xvdc:[rwm] --device=/dev/sdd \ --device=/dev/zero:/dev/nulo -i -t ubuntu ls -l /dev/&#123;xvdc,sdd,nulo&#125; 6.3. 容器使用静态 IP 及配置主机名 参考官方网络配置：https://docs.docker.com/engine/reference/run/#network-settings 6.3.1. 静态 IP 12345678# create a user_define networkdocker network create --subnet=100.64.143.0/24 vpn_nat_network# run with argsdocker run -d \ --network vpn_nat_network \ --ip 100.64.143.2 \ ... 6.3.2. 指定主机名 1docker run -it --hostname=`hostname` ... 6.4. 容器启动时设置容器内参数 12345678910111213141516171819202122232425262728# 在运行时，设置主机名docker run -it --add-host=docker:10.180.0.1 debian# 在 docker-compose 中设置extra_hosts: - "somehost:162.242.195.82" - "otherhost:50.31.209.229"# 直接设置 sysctl（不能与 --network=host 同用 ）docker run --sysctl net.ipv4.ip_forward=1 ubuntu# 在 docker-compose 中设置sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0# 设置容器的 ulimit，一般不需要设置# 因为 /lib/systemd/system/docker.service 中已经设置得很大了docker run --ulimit nofile=1024:1024 --rm debian sh -c "ulimit -n"# 在 docker-compose 中设置ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 6.5. Docker 重启 daemon 不重启 container 123# 以下二种方法任一种都可以- 将 /etc/docker/daemon.json 中的 "live-restore" 设置为 true，然后 SIGHUP（kill -HUP PID）- sudo dockerd --live-restore 6.6. Docker Daemon 的配置文件 可以使用 –config-file 指定，默认位置为 /etc/docker/daemon.json 123456789101112131415161718192021222324252627282930313233&#123; "authorization-plugins": [], "bridge": "", "cluster-advertise": "", "cluster-store": "", "debug": true, "default-ulimits": &#123;&#125;, "disable-legacy-registry": false, "dns": [], "dns-opts": [], "dns-search": [], "exec-opts": [], "fixed-cidr": "", "graph": "", "group": "", "hosts": [], "insecure-registries": [], "labels": [], "live-restore": true, "log-driver": "", "log-level": "", "mtu": 0, "pidfile": "", "raw-logs": false, "registry-mirrors": [], "storage-driver": "", "storage-opts": [], "swarm-default-advertise-addr": "", "tlscacert": "", "tlscert": "", "tlskey": "", "tlsverify": true&#125; 7. 容器资源限制 7.1. 在 docker-compose.yml 中限制 12345cpu_shares: 73cpu_quota: 50000cpuset: 0,0mem_limit: 300mmemswap_limit: 300m 8. Docker 的 API 操作 123456789# 镜像curl --unix-socket /var/run/docker.sock http://localhost/images/json# eventscurl --no-buffer -XGET --unix-socket /var/run/docker.sock http://localhost/events# container 信息curl --unix-socket /var/run/docker.sock \ "http://localhost/containers/json?all=1&amp;before=8dfafdbc3a40&amp;size=1" 9. Docker 小技巧 9.1. 已运行容器通过 iptbles 来 nat 123456789101112# DOCKER DNATiptables -t nat -A DOCKER -p tcp --dport 3306 -j DNAT --to-destination 172.16.19.2:3306# Filteriptables -A DOCKER -d 0.0.0.0 ! -i docker0 -o docker0 -p tcp -m tcp --dport 3306 -j ACCEPT# 上面那条不行的，用下面这条iptables -A DOCKER -p tcp -m tcp --dport 3306 -j ACCEPT# POSTROUTING(有时需要)iptables -t nat -A POSTROUTING -s 172.16.19.0/16 -d 172.16.19.0/16 -p tcp -m tcp --dport 3306 -j MASQUERADEiptables -t nat -A POSTROUTING -p tcp -m tcp --dport 3306 -j MASQUERADE 9.2. 使服务监听在指定的接口上 12# 创建自定义的接口docker network create -o "com.docker.network.bridge.host_binding_ipv4"="192.168.17.1" bridge2 1234567891011121314version: "3"services: test: image: busybox command: sleep 60 ports: - "7560:8080" networks: - bridge2 # ----&gt; 这里使用了自已创建的接口networks: bridge2: external: true 9.3. set metadata on container 12345678910# (如下设置了一个 my-label=""和 com.example.foo=bar)docker run -l my-label --label com.example.foo=bar ubuntu bashdocker run --label-file ./labels ubuntu bash# cat ./labelscom.example.label1="a label"# this is a commentcom.example.label2=another\ labelcom.example.label3 9.4. 从 container 的变化中新建一个 image docker commit $CONTAINER_ID [REPOSITORY[:TAG]] 9.5. 备份容器中的数据（将容器中的数据目录拷贝至当前目录下） docker run --rm --volume-from dbdata -v ${pwd}:/backup ubuntu tar cvf /backup/backup.tar /dbdata 10. Docker Inspect 10.1. 镜像和实例名字重名，使用 –type 区分 1docker inspect --type=image rhel7 10.2. 获取正在运行的容器 日志文件路径 及 日志清理 12345678910echo "" &gt; $(docker inspect --format='&#123;&#123;.LogPath&#125;&#125;' &lt;container_name_or_id&gt;)# set on docker startdockerd ... --log-opt max-size=10m --log-opt max-file=3# You can also set this as part of your daemon.json file instead of modifying your startup scripts:&#123; "log-driver": "json-file", "log-opts": &#123;"max-size": "10m", "max-file": "3"&#125;&#125; 10.3. 获取正在运行的容器 IP 的示例 1234567docker inspect \ --format='&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125; &#123;&#123;end&#125;&#125;' \ rancher-server# use jq or go template(有些查不全，不推荐使用)docker inspect rancher-server | jq -r '.[0].NetworkSettings.IPAddress'docker inspect --format '&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' rancher-server 或使用如下脚本 docker-ip 123456cat &lt;&lt;EOF &gt;/usr/local/bin/docker-ip#!/bin/bashexec docker inspect --format=&apos;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125; &#123;&#123;end&#125;&#125;&apos; &quot;\$@&quot;EOFchmod a+x /usr/local/bin/docker-ip 10.4. 解析格式化 12# 小写docker inspect --format "&#123;&#123;lower .Name&#125;&#125;" rancher-server 10.5. Listing all port bindings 12345docker inspect \--format='&#123;&#123;range $p, $conf := .NetworkSettings.Ports&#125;&#125; &#123;&#123;$p&#125;&#125; -&gt; &#123;&#123;(index $conf 0).HostPort&#125;&#125; &#123;&#123;end&#125;&#125;' \rancher-server 80/tcp -&gt; 80 10.6. Getting size、pid、mount、image 1234567891011121314# size docker inspect -s rancher-server | grep -i size# piddocker inspect --format &#123;&#123;.State.Pid&#125;&#125; rancher-server# mountdocker inspect --format '&#123;&#123;json .Mounts&#125;&#125;' rancher-server# imagedocker inspect -f '&#123;&#123;.Config.Image&#125;&#125;' rancher-server# log driverdocker inspect -f '&#123;&#123;.HostConfig.LogConfig.Type&#125;&#125;' rancher-server 详见：https://docs.docker.com/engine/admin/logging/overview/ 11. Docker 清理方案 11.1. 清理 123456789101112docker system prunedocker ps -a | grep 'weeks ago' | awk '&#123;print $1&#125;' | xargs --no-run-if-empty docker rm# 停止容器的不一定都是需要清理的docker rm $(docker ps -q -f status=exited)docker images | grep "&lt;none&gt;" | awk '&#123;print $3&#125;' | xargs docker rmidocker volume rm $(docker volume ls -qf dangling=true)docker rmi $(docker images -qf "dangling=true") 点击查看 docker 清理方案 12345678910111213docker-cleanup-volumesManage data in containersremove-orphan-images.shDeleting images from a private docker registrydelete-docker-registry-image（support v2）Cleaning up unused DockerHow to remove old Docker containersImplement a &apos;clean&apos; commanddocker-cleanup-volumes.shhttps://docs.docker.com/docker-trusted-registry/soft-garbage/docker-cleanupdocker-gc https://github.com/yangtao309/yangtao309.github.com/issues/1 Docker 架构图]]></content>
  </entry>
  <entry>
    <title><![CDATA[Rancher 安装]]></title>
    <url>%2Fdocker%2FRancher%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[1. 安装 Rancher 1.1. 单机安装 v1.6.x 12345678910111213141516171819202122232425# 下载 rancher/server 镜像 docker pull rancher/server# 单实例启动 (使用默认自带的数据库)# 如果需要开启 Prometheus 的监控，加入下面二行 # -e CATTLE_PROMETHEUS_EXPORTER=true \# -p 9108:9108 \docker run -d --restart=always \-v /opt/svicloud/rancher/server_db:/var/lib/mysql \--name rancher-server \-p 8080:8080 \rancher/server# 外置数据库启动 docker run -d --restart=always -p 8080:8080 -p 9345:9345 \--name rancher-server \rancher/server \--db-host mysql-lb.mysql.dongcj.krrish.top \--db-port 3306 \--db-user root \--db-pass mogK**** \--db-name cattle# 然后，浏览器打开 http://&lt;SERVER_IP&gt;:8080 即可 1.2. 单机安装 v.2.x 1234567891011# 下载 rancher/rancher 镜像 docker pull rancher/rancher# 单实例启动 (使用默认自带的数据库)docker run -d --restart=always \--name rancher-server \-p 80:80 \-p 443:443 \rancher/rancher# 然后，浏览器打开 http://&lt;SERVER_IP&gt; 即可 2. 其它安装选项 2.1. HA 模式安装（可选） 安装一个外部 主从模式 的 MySQL 在主备两边执行 12345678910111213141516docker run -d --restart=always -p 8080:8080 -p 9345:9345 \ --name rancher-server rancher/server \ --db-host myhost.example.com \ --db-port 3306 \ --db-user username \ --db-pass password \ --db-name cattle \ --advertise-address &lt;IP_of_the_Node&gt; db.cattle.database=mysqldb.cattle.username=cattledb.cattle.password=cattledb.cattle.mysql.host=localhostdb.cattle.mysql.port=3306db.cattle.mysql.name=cattle# All values above are the defaults except db.cattle.database. If the defaults are fine, then all you need to set is db.cattle.database=mysql. 2.2. 启动集群模式（可选） 12345# 手动启动主 docker run -d --restart=always -p 8080:8080 -p 9345:9345 --name rancher-server rancher/server --db-host 192.168.1.174 --db-port 3306 --db-user cattle --db-pass cattle --db-name cattle --advertise-address 192.168.1.174# 手动启动备 docker run -d --restart=always -p 8080:8080 -p 9345:9345 --name rancher-server rancher/server --db-host 192.168.1.174 --db-port 3306 --db-user cattle --db-pass cattle --db-name cattle --advertise-address 192.168.1.184 2.3. 设置 Rancher SSL（可选） 12345678910111213mkdir -p /opt/svicloud/rancher/proxy/certscp cert.pem key.pem /opt/svicloud/rancher/proxy/certsdocker run -d \--restart=always \--name rancher-server-ssl \--link rancher-server \-p 80:80 -p 443:443 \-e 'RANCHER_URL=console.dongcj.com' \-e 'RANCHER_CONTAINER_NAME=rancher-server' \-e 'RANCHER_PORT=8080' \-v /opt/svicloud/rancher/proxy/certs:/etc/nginx/external/ \codedevote/nginx-ssl-proxy-rancher 3. Rancher 监控告警 3.1. 用户应用监控 3.1.1. 在 Rancher 外 12345678910# 使用 rancher-alarms 进行监控, 可参考：[rancher-alarms](E:\01-Documents\02-VM、docker、CaaS\01-Docker\01-Docker_Tools\02-Monitoring、Alert、HealthCheck、Perf\rancher-alarms(rancher 告警，email&amp;slack))docker run -d \--name rancher-monitor-cs --restart=always \-e RANCHER_ADDRESS=console.sviyun.com:8080 \-e RANCHER_ACCESS_KEY=8C67EC02435BFD2CAC73 \-e RANCHER_SECRET_KEY=LKb3Ckj4FpfgGT1ea2ZGGxyxPAJ9yeKa37UVRVhi \-e RANCHER_PROJECT_ID=1a7 \-e ALARM_SLACK_WEBHOOK_URL=https://hooks.slack.com/services/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 \--name rancher-alarms \ndelitski/rancher-alarms 3.1.2. 在 Rancher 内 12345678# using rancher-compose CLIrancher-alarms: image: ndelitski/rancher-alarms environment: ALARM_SLACK_WEBHOOK_URL:https://hooks.slack.com/services/:UUID labels: io.rancher.container.create_agent: true io.rancher.container.agent.role: environmen 3.1-1 3.2. 基础服务监控 3.3. 主机监控（只提供了 API，没有告警等） 4. Rancher 网络与 DNS 4.1. 自定义加入 rancher 网络 在启动参数中加入 --label io.rancher.container.network=true，这样网络就会有 rancher 的网络 IP 4.2. 查询 DNS 的所有记录 123# external 的 DNS 设置方法相同 # 进入 network-services-metadata-dns-X.cat /etc/rancher-dns/answers.json 注意：在独立的容器中（自建的），DNS 只保留最后一个 5. Rancher LB 设置 5.1. http redirect to https 按照如下模式，自定义请求头信息 在 自定义 Haproxy.cfg 中增加以下内容 所有跳转 1234frontend 80 bind *:80 mode http redirect scheme https code 301 if !&#123; ssl_fc &#125; 所有跳转但排除 docs.svicloud.com 1234frontend 80 bind *:80 mode http redirect scheme https code 301 if !&#123; hdr(Host) -i docs.svicloud.com &#125; !&#123; ssl_fc &#125; 5.2. 使用 IP Hash 在 自定义 Haproxy.cfg 中增加以下内容 : 1balance source 1backend payms_online_backend]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>docker</tag>
        <tag>caas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用命令]]></title>
    <url>%2Flinux%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[[+] 新增 [-] 删除 [^] 升级 [#] 修复 1. 高亮 tail -f 搜索 less xxx.log 搜索你要高亮的关键字 SHIFT+F，进入 follow 模式 2. timedatectl 修改时间 https://www.cnblogs.com/EasonJim/p/8111902.html 3. pkill 1pkill -f -SIGUSR1 /app/letsencrypt_service || pkill -USR1 -f /app/letsencrypt_service 4. Windows 4.1. Windows mount 网络共享为一个文件夹 12net use \\192.168.11.111\public\datamklink /d d:\ccc \\192.168.11.111\public\data 4.2. Windows 网络设置 123ipconfig | findstr /c:&quot;IPv4&quot;sed -i -e &quot;s/$/\x0d/g&quot; $&#123;MountPoint&#125;/temp/postAfter.d/m01.configureNetworkInterfaces.batnetsh interface ip show interfaces &quot; 本地连接 &quot; 4.3. windows 如何删除隐藏设备 123# 打开隐藏设备 set devmgr_show_nonpresent_devices=1devmgmt.msc 4.4. chrome 删除某个域名缓存 打开 chrome://net-internals/#hsts， 拉至最下，删除域名 4.5. Mount webdav 12# 安装 fuse, davfs2, neon-develmount.davfs &lt;http://192.168.3.3/webdav /mnt/&gt; 5. diff &amp; patch 单个文件 123diff -uN from-file to-file &gt;to-file.patchpatch -p0 &lt; to-file.patchpatch -RE -p0 &lt; to-file.patch 多个文件 123diff -uNr from-docu to-docu &gt;to-docu.patchpatch -p1 &lt; to-docu.patchpatch -R -p1 &lt;to-docu.patch 6. Linux IP 6.1. IP 地址过滤 12345678910# this is the best methodip route get 8.8.8.8 | grep src | awk '&#123; i=1; while(i&lt;NF) &#123; if ($i =="src") print $(i+1); i++ &#125;&#125;'ip addr show eth0 | awk '/inet /&#123;split($2,x,"/");print x[1]&#125;'ifconfig eth0 | awk '&#123;if ($1 =="inet"&amp;&amp; $3 ~ /^Bcast/) print $2&#125;' | awk -F: '&#123;print $2&#125;'ifconfig -a | grep -oE '[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;'| head -1ifconfig -a | perl -e '&#123;while(&lt;&gt;)&#123;if(/inet (?:addr:)?([\d\.]+)/i)&#123;print $1,"\n";last;&#125;&#125;&#125;' 12345678910111213# get the ether listNET_DEV_PREFIX="^eno|^eth|^em|^br|^bond"NET_ETHER_LIST=`ifconfig -a | egrep '^[^]' | awk '&#123; print $1 &#125;' | egrep "$&#123;NET_DEV_PREFIX&#125;" | tr -d ':' | xargs`[-z "$NET_ETHER_LIST" ] &amp;&amp; echo "Can not get the network ether list, exit" &amp;&amp; exit 1# get the first ip &amp; maskFIRST_NET_ETHER=$(echo "$NET_ETHER_LIST" | awk '&#123;print $1&#125;')# on centosIP_ADDRESS_NETMASK=`ifconfig $FIRST_NET_ETHER | grep "inet addr" | sed "s/inet addr:\(.*\) Bcast:.* Mask:\(.*\)/\1 \2/" | head -1 | xargs`# on ubuntuIP_ADDRESS=`ifconfig $FIRST_NET_ETHER | grep -w "inet" | awk '&#123;print $2&#125;'` 6.2. Ubuntu IP 配置 修改 /etc/network/interface 1234567891011# The loopback network interfaceauto loiface lo inet loopback# The primary network interfaceauto eth0iface eth0 inet static address 192.168.0.20 netmask 255.255.255.0 gateway 192.168.0.1 dns-nameservers 8.8.4.4 223.5.5.5 如果有无线，删除无线信息 1rm -rf /etc/NetworkManager/system-connections 修改 /etc/hosts 1192.168.0.20 mini2 停止 network-manager、resolvconf 服务 Old Upstart： 123456stop network-managerservice resolvconf stopchkconfig resolvconf off# 8. Create an override file for the Upstart jobecho "manual" | sudo tee /etc/init/network-manager.override New Systemd： 12systemctl stop systemd-resolved resolvconf NetworkManagersystemctl disable systemd-resolved resolvconf NetworkManager 修改 /etc/resolv.conf 1unlink /etc/resolv.conf vi /etc/resolv.conf 12nameserver 8.8.4.4nameserver 223.5.5.5 正式开始 IP 配置吧 1234567891011121314151617181920212223242526auto eth0iface eth0 inet static address 192.168.88.20 netmask 255.255.255.0 network 192.168.88.0 broadcast 192.168.88.255 gateway 192.168.88.1 # dns-* options are implemented by the resolvconf package, if installed dns-nameservers 8.8.4.4 8.8.8.8# Bridge IP to eth1auto br100iface br100 inet static address 192.168.89.20 network 192.168.89.0 netmask 255.255.255.0 broadcast 192.168.89.255 gateway 192.168.89.1 bridge_ports eth1 bridge_stp off bridge_fd 0 bridge_maxwait 0 post-up echo 1 &gt; /proc/sys/net/ipv4/ip_forward post-up iptables -t nat -A POSTROUTING -s '10.10.10.0/24' -o eth0 -j MASQUERADE post-down iptables -t nat -D POSTROUTING -s '10.10.10.0/24' -o eth0 -j 1234567891011# Ubuntu 绑定多个 IPauto eth0iface eth0 inet static address 192.168.88.10 netmask 255.255.255.0 gateway 192.168.88.1auto eth0:1iface eth0:1 inet static address 192.168.8.10 netmask 255.255.255.0 6.3. 实时生效 IP 桥接配置 1234567brctl addbr br0 # 新建一个桥接虚拟网卡 ip link set br0 upip addr add 10.8.255.181/24 dev br0ip addr del 10.8.255.181/24 dev eth0brctl addif br0 eth0 # 将 eth0 加入到 br0ip route del defaultip route add default via 10.8.255.1 dev br0 6.4. CentOS IP 配置 1234567891011121314151617181920212223242526272829303132vi /etc/sysconfig/network-scripts/ifcfg-br0DEVICE="br0"NM_CONTROLLED="NO"ONBOOT=yesTYPE=BridgeBOOTPROTO=staticIPADDR=192.168.88.1PREFIX=24GATEWAY=192.168.88.254DNS1=192.168.88.1DOMAIN=szhcf.com.cnDEFROUTE=yesIPV4_FAILURE_FATAL=yesIPV6INIT=noNAME="System br0"# 原来的 eth0 去掉 IP 相关信息 vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE="eth0"HWADDR="14:DA:E9:07:C6:B6"NM_CONTROLLED=noONBOOT="yes"#IPADDR=192.168.88.1#NETMASK=255.255.255.0#GATEWAY=192.168.88.254#DNS1=192.168.8.1#DEFROUTE=yes#IPV4_FAILURE_FATAL=yes#IPV6INIT=noNAME="System eth0"#UUID=5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e09BRIDGE=br0 6.5. RedHat 绑定多个 IP 12345678910111213141516171819202122cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0:1 DEVICE='eth0'TYPE='Ethernet'STARTMODE='onboot'BOOTPROTO='static'IPADDR='172.16.12.139/16'NETMASK='255.255.0.0'GATEWAY='172.16.0.254'DNS='8.8.8.8'DNS_1='172.16.12.110'BROADCAST=''ETHTOOL_OPTIONS=''MTU=''NAME=''NETWORK=''REMOTE_IPADDR=''USERCONTROL='no'IPADDR_1='10.100.150.1'NETMASK_1='255.255.0.0'LABEL_1='1' # ＝＝》 这个必须添加 6.6. 更新网域内的 arp 1arping -U 10.85.138.111 -A -I br0 -c 1 # （需要 10.85.138.111 这个 IP 在本机上） 7. snip 7.1. find 按时间查找文件 12345# 不区分大小写，3 分钟内，排除 /proc* 和 /sys/*find / -name '*' -type f -mmin -3 -regextype "posix-egrep" ! -iregex "/proc.*" ! -iregex "/sys.*"# find 排除文件 rm -f md5sums; find -type f -not -name md5sums -not -name boot.cat -exec md5sum &#123;&#125; \; &gt;&gt; md5sums.txt 8. rpm usage 12345678910111213rpm -qa # 查看系统中所有已经安装的包：rpm -qf &lt; 文件名 &gt; # 查询一个已经安装的文件属于哪个软件包 rpm -ql 软件名 # 查询已安装软件包都安装到何处 rpm -qi 软件名 # 查询一个已安装软件包的信息 rpm -qc 软件名 # 查看一下已安装软件的配置文件 rpm -qd 软件名 # 查看一个已经安装软件的文档安装位置 rpm -qR 软件名 # 查看一下已安装软件所依赖的软件包及文件 rpm -qpi file.rpm # 查看一个软件包的用途、版本等信息 rpm -qpl file.rpm # 查看一件软件包所包含的文件 rpm -qpd file.rpm # 查看软件包的文档所在的位置 rpm -qpc file.rpm # 查看一个软件包的配置文件 rpm -qpR file.rpm # 查看一个软件包的依赖关系 9. apt-get、dpkg、apt-cache 1234567891011121314151617181920212223apt-get install packagename # 安装一个新软件包（参见下文的 aptitude）apt-get remove packagename # 卸载一个已安装的软件包（保留配置文件）apt-get --purge remove packagename # 卸载一个已安装的软件包（删除配置文件）apt-get autoclean apt # 所以如果需要空间的话，可以让这个命令来删除你已经删掉的软件 apt-get clean # 这个命令会把安装的软件的备份也删除，不过这样不会影响软件的使用的。apt-get upgrade # 更新所有已安装的软件包 apt-get dist-upgrade # 将系统升级到新版本 dpkg -i --force-overwrite-i package # 强制安装软件 dpkg -i --force-all package # 不顾一切的强制安装软件 dpkg -r --purge --force-deps package # 强制移除软件 dpkg -P package # 删除包（包括配置文件）dpkg -l "*package*" # 显示该包的版本等相关信息 (可通配)dpkg --get-selections # 列出系统中所有安装的软件 dpkg -L package # 列出与该包关联的文件 dpkg -I package # 显示特定包的详细信息 dpkg -unpack package.deb # 解开 deb 包的内容 dpkg -s package # 报告特定包的状态 dpkg -S keyword # 搜索所属的包内容 dpkg -c package.deb # 列出 deb 包的内容 9.1. column detail 12345678910111213141516171819202122First column: Desiredu for Unknowni for Installr for Removep for Purgeh for HoldSecond column: Statusn for Not Installedi for Installedc for Config-filesu for Unpackedf for Failed-configh for Half-installedThird column: Err? (error?) — If in uppercase, bad errors. for (none)h for Holdr for Reinst-requiredx for both-problems# 11. apt-file search]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Harbor 支持 Https]]></title>
    <url>%2Fm%2FHarbor%E5%AE%89%E8%A3%85%E5%8F%8A%20API%2F</url>
    <content type="text"><![CDATA[1. Install 1.1. 基础配置 将包下载并解压至 /opt/svicloud/tools/harbor 根据实际情况修改 harbor.cfg 123456hostname = ci.svicloud.comui_url_protocol = httpsharbor_admin_password = Changeme_123db_password = Changeme_123clair_db_password = Changeme_123 新建目录并将证书 server.crt 和 server.key 放置于目录 1mkdir -p /data/cert/ 1.2. 高级配置（可选） 1.2.1. 配置 Clair 和 Notray clair 是 coreos 开源的容器漏洞扫描工具，在容器逐渐普及的今天，容器镜像安全问题日益严重。clair 是目前少数的开源安全扫描工具，主要提供 OS（centos，debian，ubuntu 等）的软件包脆弱性扫描。 clair 架构 Notary 是一套 docker 镜像的签名工具， 用来保证镜像在 pull，push 和传输工程中的一致性和完整性。 避免中间人攻击，避免非法的镜像更新和运行。 Notary 架构 1234567891011121314151617181920export HARBOR_HOME=/opt/svicloud/tools/harborcd $HARBOR_HOME# 删除所有docker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml \ -f ./docker-compose.clair.yml down -v ## 这里会干掉所有已有容器，包括已经下载了漏洞库的 clair# 重新编辑下，可以加一些高级配置vim harbor.cfg# 启动所有(chartmuseum 从 1.6.0 版本才支持)./prepare --with-notary --with-clair --with-chartmuseum./install.sh --with-notary --with-clair --with-chartmuseum# restartdocker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml \ -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml downdocker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml \ -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml up -d 1.2.2. 限制访问的网络 1234567# docker-compose.ymlnetworks: harbor: external: false ipam: config: - subnet: xxx.xxx.xxx.xxx/27 1.2.3. 修改 harbor 文本显示（本地定制化） 修改 docker-compose.yml 找到 ui 部分 12345678ui: image: vmware/harbor-ui:v1.2.2 container_name: harbor-ui env_file: - ./common/config/ui/env restart: always volumes: - /harbor-data/custom/ui-lang:/harbor/static/i18n/lang ui-lang 文件制作： 12mkdir -p /harbor-data/custom/ui-lang &amp;&amp; cd /harbor-data/custom/ui-lang wget https://github.com/vmware/harbor/blob/master/src/ui_ng/src/i18n/lang/zh-cn-lang.json 1.2.4. 修改标题颜色（区分不同环境） 修改 docker-compose.yml 找到 ui 部分 12345678ui: image: vmware/harbor-ui:v1.2.2 container_name: harbor-ui env_file: - ./common/config/ui/env restart: always volumes: - /harbor-data/xdf/ui/clarity-ui.min.css:/harbor/static/clarity-ui.min.css:z 将原来容器中的 / harbor/static/clarity-ui.min.css 文件下载出来，修改如下样式： 找到 CSS 类： header.header-5 1header.header-5,.header.header-5&#123;background-color:#CE0606&#125; 2. watchdog 将 harbor_watchdog.sh 拷贝至 harbor 服务器，并设置 crontab，可见脚本注释 3. 同步设置 3.1. 方案 CS (registry.svicloud.com) — 全同步 —&gt; SZ (ci.svicloud.com) — 部分同步 —&gt; FR (registry.svicloud.com) 3.2. 关于国内外域名相同的方案 方法有二种： 1. 在深圳 harbor 服务器上，设置 DNS 为 1.1.1.1。 这样的话，深圳解析到的地址和国外解析到的地址一样，这样同步时就可以从深圳同步向法国了（推荐方法） 2. 在 ui 这个容器中设置 registry.svicloud.com 的 IP 地址（未测试是否完全可用） 3.3. 设置 镜像的 标签 不会同步 CS 中所有 项目，设置为全同步向 SZ 4. API 4.1. harbor-go-client(推荐) https://github.com/moooofly/harbor-go-client 4.2. 原生 API 12345678910111213141516## 4.1. 会收到一条没有认证的消息，这个正常，返回一定是 401curl -i https://registry.svicloud.com/v2/_catalog# 5. 请求 Tokencurl -i -k -u admin:Changeme_123 \ https://registry.svicloud.com/service/token?account=admin\&amp;service=harbor-registry\&amp;scope=repository:os/svi-centos7:pull,push# 6. Header 中带上 Tokencurl -k -v -H "Content-Type: application/json" -H "Authorization: Bearer THIS_IS_LONG_TOKEN" \ -X GET https://registry.svicloud.com/v2/os/svi-centos7/manifests/latest# 7. 查出某镜像的 tag 列表curl https://registry.svicloud.com/v2/dongcj/webserver/tags/list# 8. 查看某镜像的详细信息curl https://registry.svicloud.com/v2/dongcj/webserver/manifests/v0.1 5. Harbor 镜像删除问题 原始需求：使用过程中，一般情况都只是向 harbor 上传 image ，但是几乎没有人会主动进行删除，导致 image 积累越来越多；所以希望可以按照某种策略把最近不常用的 image 删除掉； 官方文档给出的删除说明如下： Repository deletion runs in two steps. First, delete a repository in Harbor’s UI. This is soft deletion. You can delete the entire repository or just a tag of it. After the soft deletion, the repository is no longer managed in Harbor, however, the files of the repository still remain in Harbor’s storage. CAUTION: If both tag A and tag B refer to the same image, after deleting tag A, B will also get deleted. Next, delete the actual files of the repository using the registry’s garbage collection(GC). Make sure that no one is pushing images or Harbor is not running at all before you perform a GC. If someone were pushing an image while GC is running, there is a risk that the image’s layers will be mistakenly deleted which results in a corrupted image. So before running GC, a preferred approach is to stop Harbor first. Run the below commands on the host which Harbor is deployed on to preview what files/images will be affected: 12$ docker-compose stop$ docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect --dry-run /etc/registry/config.yml NOTE: The above option “–dry-run” will print the progress without removing any data. Verify the result of the above test, then use the below commands to perform garbage collection and restart Harbor. 12$ docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect /etc/registry/config.yml$ docker-compose start For more information about GC, please see GC. 这里有一个问题需要弄清楚：即删除镜像的过程中需要注意哪些问题？ 详见《Garbage Collection》]]></content>
  </entry>
  <entry>
    <title><![CDATA[Rfw-RemoteFirewall 远程管理防火墙]]></title>
    <url>%2Flinux%2Fsecurity%2FRfw-RemoteFirewall%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[install &gt; client: curl client (eg: 116.23.45.8) &gt; server: rfw servers (default port: 7393) install rfw on ALL server(on client &amp; server) $ git clone https://github.com/securitykiss-com/rfw.git $ cd rfw &amp;&amp; python setup.py install generate remote crt(on client) $ cd /etc/rfw/deploy/ $ rfwgen 11.11.11.11 $ rfwgen 22.22.22.22 # will generate the follow files . ├── client │ └── ca.crt ├── offline │ └── ca.key ├── server_11.11.11.11 │ ├── server.crt │ └── server.key └── server_22.22.22.22 ├── server.crt └── server.key copy key to server 12345# on master serverscp /etc/rfw/deploy/server_11.11.11.11/server.key root@11.11.11.11:/etc/rfw/ssl/scp /etc/rfw/deploy/server_11.11.11.11/server.crt root@11.11.11.11:/etc/rfw/ssl/scp /etc/rfw/deploy/server_22.22.22.22/server.key root@22.22.22.22:/etc/rfw/ssl/scp /etc/rfw/deploy/server_22.22.22.22/server.crt root@22.22.22.22:/etc/rfw/ssl/ edit the server config $ vi /etc/rfw/rfw.conf outward.server.certfile = /etc/rfw/ssl/server.crt outward.server.keyfile = /etc/rfw/ssl/server.key auth.username = your_username_here auth.password = your_password_here $ vi /etc/rfw/white.list 116.23.45.8 start rfw(on server) $ rfw &amp; $ iptables -L -n Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 116.23.45.8 0.0.0.0/0 tcp dpt:7393 DROP tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:7393 Chain FORWARD (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination ACCEPT tcp -- 0.0.0.0/0 116.23.45.8 tcp spt:7393 DROP tcp -- 0.0.0.0/0 0.0.0.0/0 tcp spt:7393 test on client # block some bad IP for 5 minutes: $ curl -i --cacert /home/me/ca.crt --user your_username_here:your_password_here -XPUT https://11.11.11.11:7393/drop/eth/1.2.3.4?expire=5m # Check if the rule is present now and not present after 5 minutes: $ curl -i --cacert /home/me/ca.crt --user your_username_here:your_password_here https://11.11.11.11:7393/list]]></content>
      <categories>
        <category>linux</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>rfw</tag>
        <tag>RemoteFirewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2.6 升级至 python2.7]]></title>
    <url>%2Flinux%2FPython2.6%E5%8D%87%E7%BA%A7%E8%87%B3python2.7%2F</url>
    <content type="text"><![CDATA[升级 python install # 一定要先安装 zlib zlib-devel openssl openssl-devel，ncurses-devel，不然安装好后没有 zlib, 和 HTTPlib $ yum -y install zlib-devel openssl-devel ncurses-devel libxml2-devel 如果要安装 MySQL-python，需要安装以下软件 $ yum -y install mysql mysql-devel 如果要安装 lxml，需要安装以下软件 $ yum -y install libxml2-devel libxslt-devel 编译安装 python 新版 $ wget http://www.python.org/ftp/python/2.7.13/Python-2.7.13.tgz # 加上 --enable-shared 解决 &quot;Cannot build PL/Python because libpython is not a shared library&quot; $ tar -xzf Python-2.7.13.tgz &amp;&amp; cd Python-2.7.13 &amp;&amp; ./configure --enable-shared $ make all &amp;&amp; make install &amp;&amp; make clean &amp;&amp; make distclean $ echo &quot;/usr/local/lib&quot; &gt;&gt;/etc/ld.so.conf $ ldconfig $ mv /usr/bin/python /usr/bin/python2.6.bak $ ln -s /usr/local/bin/python /usr/bin/python # copy bz2 module $ yes | cp -rLfap /usr/lib64/python2.*/lib-dynload/bz2.so /usr/local/lib/python2.*/ $ python -V 安装 easy_install 和 pip # 参见：[《linux 安装 easy_install 及 pip》][1] 修改 yum 中的 python 版本为 python2.6 $ vi /usr/bin/yum $ vi /usr/bin/yum-config-manager 安装一些基础软件 $ pip install readline 在 virtualenv 里安装亦可 $ pip install MySQL-python pssh flask $ pip install lxml virtualenv virtualenvwrapper websockify]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>python 升级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SMATE、XFCE、VNC 配置]]></title>
    <url>%2Flinux%2FSMATE%E3%80%81XFCE%E3%80%81VNC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1. CentOS yum 安装图像界面 (参考：http://www.ha97.com/4634.html) 1234567891011121314151617181920212223242526yum install epel-releaseyum grouplistyum groupinstall "GNOME Desktop Environment"（CentOS 5.x 安装 GNOME 桌面环境）yum groupinstall "X Window System" "Desktop"（CentOS 6.x 安装 GNOME 桌面环境）yum groupinstall [xfce | "MATE Desktop" ]（CentOS 安装 xfce 桌面环境，可选）# 查看 runlevelsystemctl get-default || runlevel# to runlevel 5(to change runlevel 3, change to `multi-user.target`)systemctl isolate graphical.target# Start the GUI on bootsystemctl set-default graphical.target# 查看 display managerls -l /etc/systemd/system/display-manager.service# 切换 display managersystemctl disable gdm &amp;&amp; systemctl enable lightdm# 刷新 systemctl isolate graphical.target 2. 设置自动登陆 12345678910# 如果是 gdm，使用 gdmvi /etc/lightdm/lightdm.conf [SeatDefaults]autologin-guest=falseautologin-user=testautologin-user-timeout=0autologin-session=lightdm-autologinuser-session=ubuntugreeter-session=unity-greeter 3. Ubuntu 安装 Xfce 1apt install xfce4 4. 安装 vnc server 12345678# 安装 Xfce 要使用 vncserver，需修改 /root/.vnc/xstartup 里为 exec /bin/sh /etc/xdg/xfce4/xinitrc 即可 yum install vnc-server vnc* （CentOS 5.x 里）yum install tigervnc-server tigervnc （CentOS 6.x 里）/etc/init.d/vncserver restart# 关闭具体的 vncserver 命令 :vncserver -kill :1 http://jensd.be/125/linux/rhel/install-mate-or-xfce-on-centos-7]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>xorg</tag>
        <tag>smate</tag>
        <tag>xfce</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Printf 进行格式化]]></title>
    <url>%2Flinux%2F%E4%BD%BF%E7%94%A8printf%E8%BF%9B%E8%A1%8C%E6%A0%BC%E5%BC%8F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[1. 表格输出 123456789101112131415161718#/bin/bashdivider===============================divider=$divider$dividerheader="\n %-10s %8s %10s %11s\n"format="%-10s %08d %10s %11.2f\n"width=43printf "$header" "ITEM NAME" "ITEM ID" "COLOR" "PRICE"printf "%$width.$&#123;width&#125;s\n" "$divider"printf "$format" \Triangle 13 red 20 \Oval 204449 "dark blue" 65.656 \Square 3145 orange .7 2. 格式化 123456789101112131415161718192021222324252627282930313233343536printf "%s\n" "1" "2" "\n3"12\n3printf "%b\n" "1" "2" "\n3"123$printf "%d\n" 255 0xff 0377 3.5255255255bash: printf: 3.5: invalid number3printf "%f\n" 255 0xff 0377 3.5255.000000255.000000377.0000003.500000printf "%.1f\n" 255 0xff 0377 3.5255.0255.0377.03.5 3. 格式化 12for i in $(seq 1 10); do printf "%03d\t" "$i"; done001 002 003 004 005 006 007 008 009 010]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>printf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 升级 Kernel 及 tcp_BBR]]></title>
    <url>%2Flinux%2FLinux%E5%8D%87%E7%BA%A7kernel%E5%8F%8A%E9%85%8D%E7%BD%AEtcp_BBR%E3%80%81TFO%E3%80%81Hybla%2F</url>
    <content type="text"><![CDATA[1. 开启 BBR 123456789101112# 先查看内核是否大于 4.9，如大于 4.9echo "net.core.default_qdisc=fq" &gt;&gt; /etc/sysctl.confecho "net.ipv4.tcp_congestion_control=bbr" &gt;&gt; /etc/sysctl.conf# 打开 TFO(tcp fast open), 服务端为 3，客户端为 1echo "net.ipv4.tcp_fastopen = 3" &gt;&gt; /etc/sysctl.conf# 保存生效 sysctl -p# 查看 bbr 是否生效 lsmod | grep bbr 2. 开启高级算法 hybla 注意：此步骤不适用于 OpenVZ 或低版本内核，否则在执行最后一个步骤 sysctl -p 的时候会大量报错，如果没报错说明内核支持高级算法 hybla 等参数调整。 注意：该算法和 BBR 同属于集成于内核中的模块，当两者同时开启后，BBR 优先级最高 。所以开启 BBR 后再开这个没用。 12345678910111213141516171819echo 'fs.file-max = 51200net.core.rmem_max = 67108864net.core.wmem_max = 67108864net.core.netdev_max_backlog = 250000net.core.somaxconn = 4096net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.ip_local_port_range = 10000 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_fastopen = 3net.ipv4.tcp_mem = 25600 51200 102400net.ipv4.tcp_rmem = 4096 87380 67108864net.ipv4.tcp_wmem = 4096 65536 67108864net.ipv4.tcp_mtu_probing = 1net.ipv4.tcp_congestion_control = hybla' &gt;&gt; /etc/sysctl.conf 3. Debian、Ubuntu 升级内核 123456789101112131415161718192021# 直接使用 apt-get 安装内核 apt updateapt-cache search linux-image-extra# 安装最新的内核 apt install linux-image-extra-4.15.0-15-generic# 查看 dpkg -l | grep linux-image# 删除旧内核 apt remove &lt;OLD_KERNEL_RELEASE&gt;update-grubapt autoremovereboot# 查看一下目前的内核版本 # 应该是显示为 &lt;NEWEST_KERNEL_RELEASE&gt;uname -r 4. RHEL、CentOS 升级内核 1234567891011121314151617181920212223242526272829yum update -yrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org# 如果是 el7rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm# 如果是 el6rpm -Uvh http://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm# 安装内核 yum --enablerepo=elrepo-kernel install kernel-ml# 查看当前已安装的内核 awk -F\''$1=="menuentry " &#123;print i++ " : " $2&#125;' /etc/grub2.cfg# 设定默认内核 (centos7)grub2-set-default 0reboot# 设定默认内核 (centos6)vi /etc/grub.conf# 修改 default=&lt;ID 号 &gt;# 设定 /etc/sysctl.confnet.core.default_qdisc = fqnet.ipv4.tcp_congestion_control = bbr# 生效 sysctl -p 5. 手动安装 5.1. 下载内核二进制包 链接：http://mirrors.kernel.org/debian/pool/main/l/linux/ 5.2. 解压安装 123456ar x linux-image-4.9.0-11-generic_4.9.0-11.12_amd64_5.debbzip2 -d data.tar.bz2tar -xf data.tarinstall -m644 boot/vmlinuz-4.9.0-11-generic /boot/vmlinuz-4.9.0-11-genericcp -Rav lib/modules/4.9.0-11-generic/ /lib/modules/depmod -a 4.9.0-11-generic 5.3. 加入引导 12345dracut -f -v --hostonly -k '/lib/modules/4.9.0-11-generic' /boot/initramfs-4.9.0-11-generic 4.9.0-11-generic# 注 : centos7 和 6 的步骤不同，centos6 是 grub，需要手动自动写 , 但注意：root=UUID= 那里的 uuid 不能修改！！！；# centos7 是 grub2 可以用下面命令 :grub2-mkconfig -o /boot/grub2/grub.cfg 5.4. 修改引导顺序 1234567891011# 查看引导内有哪些内核 cat /boot/grub2/grub.cfg |grep menuentrycat /boot/grub2/grub.cfg |grep menuentryif [x"$&#123;feature_menuentry_id&#125;" = xy ]; then menuentry_id_option="--id" menuentry_id_option="" export menuentry_id_option menuentry 'CentOS Linux (4.9.0-rc8-amd64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-4.9.0-rc8-amd64-advanced-508f0c60-8ce4-48fa-a00e-8db45fa56da8' &#123; menuentry 'CentOS Linux (3.10.0-327.36.3.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-327.36.3.el7.x86_64-advanced-508f0c60-8ce4-48fa-a00e-8db45fa56da8' &#123; menuentry 'CentOS Linux (0-rescue-d45b6a27fe9641bd8979101342a4f20b) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-0-rescue-d45b6a27fe9641bd8979101342a4f20b-advanced-508f0c60-8ce4-48fa-a00e-8db45fa56da8' &#123; # 下面命令的内核名称根据系统内部查到的实际名称来替换： grub2-set-default &#39;CentOS Linux (4.9.0-rc8-amd64) 7 (Core)&#39; grub2-editenv list saved_entry=CentOS Linux (4.9.0-rc8-amd64) 7 (Core)]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>升级内核</tag>
        <tag>kernel</tag>
        <tag>bbr</tag>
        <tag>tcp_bbr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Postgresql 主从配置]]></title>
    <url>%2Fdatabase%2FPostgresql%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装好二台 postgresql 参见：http://blog.dongcj.com/database/Postgresql%E5%AE%89%E8%A3%85/ 1234567891011# 主服务器上 vi /etc/profile export PGDATA=/pgdatasource /etc/profile# 从服务器上 vi /etc/profile export PGDATA=/pgdata_backupsource /etc/profile 配置主服务器 192.168.10.11 123456789101112131415161718192021222324252627# 使用 root 帐户 mkdir /pgdatachown -R postgres:postgres /pgdata/# 配置一个账号进行主从同步 su - postgrespsql [-p 54321] # 如果修改过端口，需要指定端口 psql$ CREATE ROLE replica login replication encrypted password 'replica';# 增加 replica 用户 cd /pgdatavi pg_hba.conf host replication replica 192.168.10.12/32 md5# 配置复制参数 vi postgresql.conf wal_level = hot_standby # 主为 wal 的主机 max_wal_senders = 32 # 最多几个流复制 wal_keep_segments = 256 # 设置流复制保留最多的 log 数目，每个 log 16M wal_sender_timeout = 60s # 流复制主机发送数据的超时时间 max_connections = 100 # 注意：从库的 max_connections 必须要大于主库的 # 修改权限 chmod -R 700 /pgdata/# 重启 pgpg_ctl restart 配置从服务器 192.168.10.12 1234567891011121314151617181920212223242526272829# 使用 root 帐户 mkdir /pgdata_backupchown -R postgres:postgres /pgdata_backup/su - postgrespg_basebackup -F p --progress -D /pgdata_backup -h 192.168.10.11 -p 5432 -U replica --password# password is: replicacd /pgdata_backup# 编辑配置 vi recovery.conf# 如果找不到 recovery.conf，可以新建，只需要下面三行即可 recovery_target_timeline = 'latest'standby_mode = onprimary_conninfo = 'host=192.168.10.11 port=5432 user=replica password=replica'# 编辑配置 vi postgresql.confmax_connections = 1000 # (要大于主库的)hot_standby = on # 说明这台机器不仅仅是用于数据归档，也用于数据查询 max_standby_streaming_delay = 30s # 多久向主报告一次从的状态，最长的间隔时间 wal_receiver_status_interval = 5s # 间隔多久将状态信息发送给主 hot_standby_feedback = on # 如果有错误的数据复制，是否向主进行反馈 chmod -R 700 /pgdata_backup/# 启动从 pgpg_ctl start 检测配置是否成功 # 使用 ps -ef 在主从二台上检测进程状态 # 在主上应该有 sender 进程，在从上有 receiver 进程 # 在主上查看复制状态 $ psql$ select * from pg_stat_replication; # 可以看到 sender 的进程信息 主从切换命令 1234567891011121314151617181920212223242526272829303132333435# node1 上模拟主库故障 [postgres@node1 ~]$ pg_ctl stop -m f# node2 提升备库状态 [postgres@node2 ~]$ pg_ctl promote# node2 更新备数据 [postgres@node2 ~]$ createdb pgbench[postgres@node2 ~]$ pgbench -i -s 10 pgbench# node1 将以前 master 恢复为 standbypg_rewind -D /opt/pgsql/data/ --source-server='host=node2 user=postgres port=5432'vi /opt/pgsql/data/recovery.confstandby_mode = 'on'primary_conninfo = 'host=node2 user=postgres port=5432'recovery_target_timeline = 'latest'# 启动 node1 上的数据库：[postgres@node1 ~]$ pg_ctl start# 将 node1 恢复为 master[postgres@node2 ~]$ pg_ctl stop -m f[postgres@node1 ~]$ pg_ctl promote[postgres@node1 ~]$ pgbench -s 10 -T 60 pgbench# 恢复 node2 为 standby：[postgres@node2 ~]$ pg_rewind -D /opt/pgsql/data/ --source-server='host=node1 user=postgres port=5432'[postgres@node2 ~]$ mv /opt/pgsql/data/recovery.done /opt/pgsql/data/recovery.conf# 修改 node2 为 node1vi /opt/pgsql/data/recovery.conf # 启动 node2 上的数据库：[postgres@node2 ~]$ pg_ctl start]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgresql</tag>
        <tag>pg recovery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PXE 安装与设定]]></title>
    <url>%2Flinux%2FPXE%E5%AE%89%E8%A3%85%E4%B8%8E%E8%AE%BE%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[安装软件 # 安装的软件： dhcp-3.0.5-7.el5.x86_64.rpm vsftpd-2.0.5-10.el5.x86_64.rpm(不须装) xinetd-2.3.14-10.el5.x86_64.rpm tftp-server-0.42-3.1.x86_64.rpm pykickstart-0.43.3-1.el5.noarch.rpm system-config-kickstart-2.6.19.1-1.el5.noarch.rpm syslinux # 关闭 selinux &amp; iptables dhcp 配置 ddns-update-style interim; ignore client-updates; allow booting; allow bootp; class &quot;pxeclients&quot;{match if substring(option vendor-class-identifier,0,9) = &quot;PXEClient&quot;; filename &quot;/pxelinux.0&quot;; next-server 10.85.138.9; } subnet 10.85.138.0 netmask 255.255.254.0 { option routers 10.85.138.1; option subnet-mask 255.255.254.0; option domain-name &quot;gwcloud.com&quot;; option domain-name-servers 10.85.138.1; option time-offset -18000; # Eastern Standard Time range dynamic-bootp 10.85.138.100 10.85.138.249; default-lease-time 21600; max-lease-time 43200; } 增加 tftp 文件 拷文件至 tftpboot(注：menu.c32 和 pxelinux.0 要从本机拷贝，否则 TIMEOUT 无效！) $ cp /usr/share/syslinux/menu.c32 /var/lib/tftpboot/ $ cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ $ cp /mnt/isolinux/initrd.img /var/lib/tftpboot/isolinux $ cp /mnt/isolinux/vmlinuz /var/lib/tftpboot/isolinux $ cp /mnt/isolinux/isolinux.cfg /tftpboot/pxelinux.cfg/default # default 文件也可以自己修改 配置 kickstart # 在 /tftpboot/pxelinux.cfg/default 中添加 KS 入口 label linux menu label ^Install or upgrade an existing system menu default kernel vmlinuz append initrd=isolinux/initrd.img ks=ftp://10.85.138.9/pub/ks.cfg # 修改 kickstart 自动安装 linux(见安装文件) 附录：完整 DHCP 样例 ddns-update-style interim; ddns-updates on; ignore client-updates; allow booting; # for pxe only allow bootp; # for pxe only authoritative; # Do not know what is meaning?? class &quot;pxeclients&quot;{match if substring(option vendor-class-identifier,0,9) = &quot;PXEClient&quot;; # for pxe # match if substring(option vendor-class-identifier, 0, 4) = &quot;MSFT&quot;; # for normal dhcp # option host-name = config-option server.ddns-hostname; # set the server&#39;s hostname, only for linux??? ddns-hostname = concat(&quot;v&quot;, suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 1, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 2, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 3, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 4, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 5, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 6, 1))), 2) ); filename &quot;/pxelinux.0&quot;; # for pxe only next-server 192.168.88.1; # for pxe only } class &quot;MSFT&quot; {match if substring(option vendor-class-identifier, 0, 4) = &quot;MSFT&quot;; option host-name = config-option server.ddns-hostname; #ddns-hostname = concat(&quot;v&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 1, 6))); #ddns-hostname = pick (option host-name, concat(&quot;v&quot;, # Windows instances will apply for a hostname by default ddns-hostname = concat(&quot;v&quot;, suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 1, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 2, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 3, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 4, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 5, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 6, 1))), 2) ); } option host-name = config-option server.ddns-hostname; ddns-hostname = pick (option host-name, concat(&quot;v&quot;, suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 1, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 2, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 3, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 4, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 5, 1))), 2), suffix(concat(&quot;0&quot;, binary-to-ascii(16, 8, &quot;&quot;, substring (hardware, 6, 1))), 2) )); set vendor-string = option vendor-class-identifier; subnet 192.168.88.0 netmask 255.255.255.0 { option routers 192.168.88.1; option subnet-mask 255.255.255.0; option domain-name &quot;gwcloud.cn&quot;; option domain-name-servers 192.168.88.1; # option host-name &quot;Server001&quot; # set the server&#39;s hostname, only for linux??? # option ntp-servers 192.168.88.1 # set the ntp server option time-offset -18000; # Eastern Standard Time range dynamic-bootp 192.168.88.100 192.168.88.200; default-lease-time 21600; max-lease-time 43200; # the next is bonding the mac to static ip address # host pc1 { # hardware ethernet 00:a0:cc:cf:9C:14; # host&#39;s mac address # fixed-address 192.168.1.30; # host&#39;s ip address }]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>dhcp</tag>
        <tag>pxe</tag>
        <tag>kickstart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Curl、resty、httpie、httpstat、wuzz 使用介绍]]></title>
    <url>%2Flinux%2FCurl%E3%80%81resty%E3%80%81httpie%E3%80%81httpstat%E3%80%81wuzz%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[1. curl 1.1. 直接下载文件并压缩 1234567export DOCKERIZE_VERION=latest &amp;&amp; \export DOCKERIZE_ARCH=dockerize-linux-amd64DOCKERIZE_DOWNLOADURL=$(curl -s https://api.github.com/repos/jwilder/dockerize/releases/$&#123;DOCKERIZE_VERION&#125; | \ jq -r ".assets[] | select(.name | test(\"$&#123;DOCKERIZE_ARCH&#125;\")) | .browser_download_url")curl -sSOL http://$DOCKERIZE_DOWNLOADURL# or curl -sSL $&#123;DOCKERIZE_DOWNLOADURL&#125; | tar zxvf - -C $&#123;MODULE_HOME&#125; 1.2. 详细信息 1234curl -v www.sina.comcurl --trace output.txt www.sina.comcurl --trace-ascii output.txt www.sina.comcurl -s --head www.sina.com 1.3. 上传文件与 post 123456789curl --form upload=@localfilename --form press=OK [URL]curl -iL --user admin:mogK+vXX --form upload=@proxy.conf http://69.172.89.60:8090/uploadercurl --cookie "name=xxx" www.example.comcurl --user username:password http://example.comcurl example.com/form.cgi?data=xxxcurl -fsSL ... 1.4. 下载网页保存为文件名 1234567curl -o [文件名] www.sina.comcurl -L www.sina.comcurl --limit-rate 1000B -O http://www.gnu.org/software/gettext/manual/gettext.htmlcurl --insecure -LJO https://packages.gitlab.com/gitlab 1.5. 增加头信息 (-H) 1234567curl -i -X GET --header "Content-Type:application/json" http://example.com# 2. 模拟服务地址（例如有些网站只能用域名访问的）curl – H Host:web-test.proxy-test.local http://192.168.1.2:8080POST：(-d)curl -i -X POST --data "data=xxx" example.com/form.cgicurl -i -X POST --data-urlencode "date=April 1" example.com/form.cgi 1.6. Referer(-e) 1curl --referer http://www.example.com http://www.example.com 1.7. User Agent 字段 (-A) 1curl --user-agent "[User Agent]" http://www.example.com 1.8. 配置压缩 12# (-I means "Fetch the HTTP-header only")curl -I http://www.111cn.net/ -H Accept-Encoding:gzip,defaltefrom 1.9. 超时设置 12--connect-timeout 3 # 3 秒连接时间 -m | --max-time 5 # 连接 5 秒后自动断开 1.10. 本地 socket 123curl --unix-socket /var/run/docker.sock http:/images/json# orcurl --unix-socket /var/run/docker.sock http://localhost/images/json 1.11. curl examples 123456789101112131415161718# zabbix 使用 API 进行认证 curl -i -X POST -H 'Content-Type:application/json' -d \ '&#123;"jsonrpc":"2.0","method":"user.authenticate","params":&#123;"user":"admin","password":"passw0rd"&#125;, \"auth": null,"id":0&#125;' http://192.168.0.54/api_jsonrpc.phpHTTP/1.1 200 OKDate: Mon, 12 Aug 2013 05:53:05 GMTServer: Apache/2.2.21 (Linux/SUSE)X-Powered-By: PHP/5.3.8Content-Length: 68Content-Type: application/json&#123;"jsonrpc":"2.0","result":"c12f74265ea3cfb772b5e1d56957645b","id":0&#125;-i|--include : 在输出中包含 HTTP 头 (如服务器名，日期，HTTP 版本等)-s|--silent : 静默模式 -X|--request : 请求 HTTP 服务，默认为 GET 1234567891011121314body='&#123;"request": &#123;"message":"Update docs (triggered by easywechat/docs).","branch":"master" &#125;&#125;'curl -s -X POST \ -H "Content-Type: application/json" \ -H "Accept: application/json" \ -H "Travis-API-Version: 3" \ -H "Authorization: token $&#123;ACCESS_TOKEN&#125;" \ -d "$body" \ https://api.travis-ci.org/repo/EasyWeChat%2Fsite/requests 2. resty 模拟请求 1234567891011121314151617# install restycurl -L http://github.com/micha/resty/raw/master/resty &gt; resty# 导入变量 . resty$ resty http://127.0.0.1:8080/data http://127.0.0.1:8080/data*$ GET /blogs.json[&#123;"id" : 1, "title" : "first post", "body" : "This is the first post"&#125;, ... ]$ PUT /blogs/2.json '&#123;"id": 2,"title":"updated post","body":"This is the new."&#125;'&#123;"id" : 2, "title" : "updated post", "body" : "This is the new."&#125;$ DELETE /blogs/2$ POST /blogs.json '&#123;"title":"new post","body":"This is the new new."&#125;'&#123;"id" : 204, "title" : "new post", "body" : "This is the new new."&#125; 3. 使用 httpie 123456789101112131415161718192021# install$ apt-get install httpie# usage$http httpie.org$ http PUT example.org X-API-Token:123 name=John$ http -f POST example.org hello=World$ http -v example.org$ http -a USERNAME POST https://api.github.com/repos/jakubroztocil/httpie/issues/83/comments \ body='HTTPie is awesome! :heart:'$ http example.org &lt; file.json$ http example.org/file &gt; file$ http --download example.org/file$ http --session=logged-in -a username:password httpbin.org/get API-Key:123$ http --session=logged-in httpbin.org/headers$ http localhost:8000 Host:example.com$ http DELETE example.org/todos/7 4. httpstat httpstat 5. wuzz wuzz]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>curl</tag>
        <tag>resty</tag>
        <tag>httpie</tag>
        <tag>httpstat</tag>
        <tag>wizz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬 Raid(megacli) 与软 Raid (Mdadm) 创建]]></title>
    <url>%2Flinux%2F%E7%A1%AC%20raid(megacli)%20%E4%B8%8E%E8%BD%AF%20raid%20(mdadm)%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[建议： 如果 raid0，1，raid1+0 可以使用软 raid, raid10 及以上不建议使用软 raid ！ 1. mega 管理硬 raid 1.1. 查看磁盘状态 123456789101112131415161718192021222324# 简略信息megasasctl a0 PERC H710 Mini encl:1 ldrv:1 batt:FAULT, low voltage a0d0 1862GiB RAID 0 1x1 optimal unconfigured: a0e32s1 a0e32s2 a0e32s3 a0e32s0 1863GiB a0d0 online a0e32s1 1863GiB ready a0e32s2 1863GiB ready a0e32s3 1863GiB ready # 或者megaraidsas-status -- Arrays informations -- -- ID | Type | Size | Status a0d0 | RAID 0 | 1862GiB | optimal -- Disks informations -- ID | Model | Status | Warnings a0e32s0 | SEAGATE ST2000NM0023 1863GiB | online a0e32s1 | SEAGATE ST2000NM0023 | ready a0e32s2 | SEAGATE ST2000NM0023 | ready a0e32s3 | SEAGATE ST2000NM0023 | ready 12345678910111213141516171819202122232425262728293031323334353637# 详细物理磁盘 (pd) 信息，主要是看 ` 框 ID` 与 ` 插槽 ID`megacli -PDlist -a0 | grep -e '^Enclosure Device ID:' -e '^Slot Number:'# ------------------------------------------------------------# 其它输出详细信息可以看看，平时可以通过这个来检查磁盘型号、状态等信息 Adapter #0 Enclosure Device ID: 32 Slot Number: 0 Drive s position: DiskGroup: 0, Span: 0, Arm: 0 Enclosure position: 1 Device Id: 0 WWN: 5000C500627EE690 Sequence Number: 2 Media Error Count: 0 Other Error Count: 0 Predictive Failure Count: 0 Last Predictive Failure Event Seq Number: 0 PD Type: SAS Raw Size: 1.819 TB [0xe8e088b0 Sectors] Non Coerced Size: 1.818 TB [0xe8d088b0 Sectors] Coerced Size: 1.818 TB [0xe8d00000 Sectors] Sector Size: 0 Firmware state: Online, Spun Up # &lt;----- 如果重建，这里显示为：rebuilding Device Firmware Level: GS0F Shield Counter: 0 Successful diagnostics completion on : N/A ... # ------------------------------------------------------------# 如果状态为重建中，可以查看重建信息megacli -PDRbld -ShowProg -PhysDrv [32:1] -aALL Rebuild Progress on Device at Enclosure 32, Slot 1 Completed 51% in 10 Minutes. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 逻辑磁盘 (LD) 信息 megacli -LDInfo -Lall -aALL# 物理磁盘(PD) 信息megacli -PDList -aALL# ------------------------------------------------------------# Display, disable or enable automatic rebuild on adapter 0:# Displaymegacli -AdpAutoRbld -Dsply -a0 Adapter 0: AutoRebuild is Enabled. Exit Code: 0x00# disablemegacli -AdpAutoRbld -Dsbl -a0 Adapter 0: AutoRebuild is Disabled. Exit Code: 0x00# enablemegacli -AdpAutoRbld -Enbl -a0 Adapter 0: AutoRebuild is Enabled. Exit Code: 0x00# ------------------------------------------------------------# Get and modify rebuild rate:# getmegacli -AdpGetProp RebuildRate -a0 Adapter 0: Rebuild Rate = 30% Exit Code: 0x00# setmegacli -AdpSetProp RebuildRate 60 -a0 Adapter 0: Set rebuild rate to 60% success. Exit Code: 0x00 1.2. Create a RAID0,1,5,6 array with MegaCli 12345678910111213# 将后面三块盘创建 raid0megacli -CfgLdAdd -r0[32:1,32:2,32:3] -a0 Adapter 1: Created VD 0 Adapter 1: Configured the Adapter!! Exit Code: 0x00# Note: to make RAID0, minimal 2 drives are required.# to make RAID1, minimal 2 drives are required.# to make RAID5, minimal 3 drives are required.# to make RAID6, minimal 4 drives are required. 1.3. Create a RAID50,raid60 array with MegaCli 12345megactl -CfgLdAdd -r50 raid0[252:2,252:3,252:4] raid1[252:5,252:6,252:7] -a0megactl -CfgLdAdd -r60 raid0[252:2,252:3,252:4,252:5] raid1[252:6,252:7,252:8,252,9] -a0# Note: to make RAID50, minimal 6 drives are required.# to make RAID60, minimal 8 drives are required. 1.4. Performance tunning 1.4.1. Read Cache 12345678910# infomegacli -LDSetProp -Cached -LAll -aAllSet Cache Policy to Cached on Adapter 0, VD 0 (target id: 0) successSet Cache Policy to Cached on Adapter 1, VD 0 (target id: 0) success# enablemegacli -LDSetProp EnDskCache -LAll -aAll Set Disk Cache Policy to Enabled on Adapter 0, VD 0 (target id: 0) success Set Disk Cache Policy to Enabled on Adapter 1, VD 0 (target id: 0) success 1.4.2. ReadAhead About ReadAhead: this feature will read more stuff and store in the cache, guessing the system may access it soon. We’re going to enable an enhanced version of readahead: the adaptative one. With this option, readahead will only be enabled if the controller receive several access to sequencial sectors. If not, it won’t be used to avoid filling cache with randon useless data (in case of randomly accessed sector). 1234567891011# enable an enhanced version of readahead: the adaptative onemegacli -LDSetProp ADRA -LALL -aALL Set Read Policy to Adaptive ReadAhead on Adapter 0, VD 0 (target id: 0) success Set Read Policy to Adaptive ReadAhead on Adapter 1, VD 0 (target id: 0) success# 如果上面失败，可以使用下面的普通『ReadAhead』功能megacli -LDSetProp RA -LALL -aALL Set Read Policy to Adaptive ReadAhead on Adapter 0, VD 0 (target id: 0) success Set Read Policy to Adaptive ReadAhead on Adapter 1, VD 0 (target id: 0) success 1.4.3. write cache Enable write cache，data will be lost! Write cache should be enabled ONLY if you have a battery pack on your controller！ 12345678910111213141516171819202122# Let's check if we have one and if it's working fine:megacli -AdpBbuCmd -GetBbuStatus -a0 | grep -e '^isSOHGood' -e '^Charger Status' -e '^Remaining Capacity' Charger Status: Complete Remaining Capacity: 1445 mAh isSOHGood: Yesmegacli -AdpBbuCmd -GetBbuStatus -a1 | grep -e '^isSOHGood' -e '^Charger Status' -e '^Remaining Capacity' Charger Status: Complete Remaining Capacity: 1353 mAh isSOHGood: Yes# enable write cachemegacli -LDSetProp WB -LALL -aALL Set Write Policy to WriteBack on Adapter 0, VD 0 (target id: 0) success Set Write Policy to WriteBack on Adapter 1, VD 0 (target id: 0) success# But disable it if the battery went broken or dischargedmegacli -LDSetProp NoCachedBadBBU -LALL -aALL Set No Write Cache if bad BBU on Adapter 0, VD 0 (target id: 0) success Set No Write Cache if bad BBU on Adapter 1, VD 0 (target id: 0) success 1.5. Show system summary 1megactl -ShowSummary -aALL 2. mdadm 管理软 raid 2.1. 硬盘分区 1234567891011121314151617181920212223242526272829303132333435363738394041# 分区格式为 Linux software raid：$ fdisk /dev/sdaWARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command'c') and change display units to sectors (command'u').Command (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-91201, default 1):Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-91201, default 91201):Using default value 91201Command (m for help): pDisk /dev/sda: 750.2 GB, 750156374016 bytes255 heads, 63 sectors/track, 91201 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x0005c259 Device Boot Start End Blocks Id System/dev/sda1 1 91201 732572001 83 LinuxCommand (m for help): tSelected partition 1Hex code (type L to list codes): fdChanged system type of partition 1 to fd (Linux raid autodetect)Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 2.2. 更改分区格式 # 按照上面的 /dev/sda 的分区例子依次给剩下的 5 块硬盘 sdc, sdd, sde, sdf, sdg 分区 $ fdisk /dev/sdc ... $ fdisk /dev/sdd ... $ fdisk /dev/sde ... $ fdisk /dev/sdf ... $ fdisk /dev/sdg ... 2.3. 创建 RAID # 在上面的 6 个相同大小的分区上创建 raid10 $ mdadm --create /dev/md0 -v --raid-devices=6 --level=raid10 /dev/sda1 /dev/sdc1 /dev/sdd1 /dev/sde1 /dev/sdf1 /dev/sdg1 mdadm: layout defaults to n2 mdadm: layout defaults to n2 mdadm: chunk size defaults to 512K mdadm: size set to 732440576K mdadm: Defaulting to version 1.2 metadata mdadm: array /dev/md0 started. # 查看磁盘阵列的初始化过程（build），根据磁盘大小和速度，整个过程大概需要几个小时： # watch cat /proc/mdstat Every 2.0s: cat /proc/mdstat Tue Feb 11 12:51:25 2014 Personalities : [raid10] md0 : active raid10 sdg1[5] sdf1[4] sde1[3] sdd1[2] sdc1[1] sda1[0] 2197321728 blocks super 1.2 512K chunks 2 near-copies [6/6] [UUUUUU] [&gt;....................] resync = 0.2% (5826816/2197321728) finish=278.9min speed=13 0948K/sec unused devices: 2.4. 给 md0 设备创建分区和文件系统 $ fdisk /dev/md0 $ mkfs.ext4 /dev/md0p1 $ mkdir /raid10 $ mount /dev/md0p1 /raid10 2.5. 修改 /etc/fstab 启动时自动挂载 123$ vi /etc/fstab ... /dev/md0p1 /raid10 ext4 noatime,rw 0 0 在上面的 /etc/fstab 文件里使用 /dev/md0p1 设备名不是一个好办法，因为 udev 的缘故，这个设备名常在重启系统后变化，所以最好用 UUID，使用 blkid 命令找到相应分区的 UUID 123$ blkid.../dev/md0p1: UUID="093e0605-1fa2-4279-99b2-746c70b78f1b" TYPE="ext4" 12345# 修改相应的 fstab，使用 UUID 挂载：$ vi /etc/fstab.../dev/md0p1 /raid10 ext4 noatime,rw 0 0**UUID=093e0605-1fa2-4279-99b2-746c70b78f1b /raid10 ext4 noatime,rw 0 0** 2.6. 查看 RAID 的状态 $ mdadm --query --detail /dev/md0 /dev/md0: Version : 1.2 Creation Time : Tue Feb 11 12:50:38 2014 Raid Level : raid10 Array Size : 2197321728 (2095.53 GiB 2250.06 GB) Used Dev Size : 732440576 (698.51 GiB 750.02 GB) Raid Devices : 6 Total Devices : 6 Persistence : Superblock is persistent Update Time : Tue Feb 11 18:48:10 2014 State : clean Active Devices : 6 Working Devices : 6 Failed Devices : 0 Spare Devices : 0 Layout : near=2 Chunk Size : 512K Name : local:0 (local to host local) UUID : e3044b6c:5ab972ea:8e742b70:3f766a11 Events : 70 Number Major Minor RaidDevice State 0 8 1 0 active sync /dev/sda1 1 8 33 1 active sync /dev/sdc1 2 8 49 2 active sync /dev/sdd1 3 8 65 3 active sync /dev/sde1 4 8 81 4 active sync /dev/sdf1 5 8 97 5 active sync /dev/sdg1 2.7. 配置 raid 的配置文件 $ echo device /dev/sdb1 /dev/sdc1 /dev/sdd1 &gt; /etc/mdadm.conf $ mdadm --detail --scan &gt;&gt; /etc/mdadm.conf 2.8. RAID 维护命令 2.8.1. 删除故障盘 $ mdadm /dev/md0 -r /dev/sdb1 2.8.2. 增加新盘 $ mdadm /dev/md0 -a /dev/sde1 2.8.3. 停止并移除阵列 123$ mdadm --stop /dev/md99 # // 停止$ mdadm -As /dev/md0 # // 启动$ mdadm --remove /dev/md99 2.8.4. 销毁系统中的阵列 1234mdadm --manage /dev/md99 --fail /dev/sd[cde]1mdadm --manage /dev/md99 --remove /dev/sd[cde]1mdadm --manage /dev/md99 --stopmdadm --zero-superblock /dev/sd[cde]1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>soft raid</tag>
        <tag>mdadm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Puppet 安装]]></title>
    <url>%2Flinux%2FPuppet%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[/etc/hosts 可以 ping 通对方域名 安装 puppet $ yum install ruby ruby-libs ruby-rdoc $ wget http://yum.puppetlabs.com/el/6/products/x86_64/puppetlabs-release-6-10.noarch.rpm ( 这个版本可以修改为最新的） $ yum update # 服务端安装 puppet-server $ yum install puppet-server # 服务端安装 puppet 图形界面（可选） $ yum install ruby-mysql mysql mod_passenger puppet-dashboard # 客户端安装 puppet $ yum install puppet service puppetmaster start $ puppet master --verbose --no-daemonize --cert_name &quot;Puppet CA: `hostname -f`&quot; $ openssl x509 -text -noout -in /var/lib/puppet/ssl/certs/ca.pem $ cat &gt; /etc/puppet/autosign.conf &lt;&lt;EOF *.xxx.com EOF $ service puppetmaster restart $ puppet cert list --all --&gt; 查看下证书，此时是没有客户机的，只有自己 在 /etc/puppet/puppet.conf 中添加 server = bigdata.xxxx.com 一行，为了方便命令都可以不用 --server bigdata.xxxx.com $ puppetd --server bigdata.xxxx.com --test 或者 $ puppet agent --no-daemonize --onetime --verbose --debug 安装 dashboard $ vi /usr/share/puppet-dashboard/config/database.yml production: database: puppet username: root password: passw0rd encoding: utf8 adapter: mysql $ vi /usr/share/puppet-dashboard/config/environment.rb config.time_zone = &#39;Beijing&#39; 初始化数据库 $ cd /usr/share/puppet-dashboard/ rake RAILS_ENV=production db:migrate 整合 Passenger 和 apache $ vi /etc/httpd/conf.d/passenger.conf LoadModule passenger_module modules/mod_passenger.so PassengerRoot /usr/lib/ruby/gems/1.8/gems/passenger-3.0.21 PassengerRuby /usr/bin/ruby PassengerHighPerformance on PassengerMaxPoolSize 12 PassengerPoolIdleTime 1500 PassengerStatThrottleRate 120 RailsAutoDetect On &lt;VirtualHost *&gt; ServerName bigdata.xxxx.com DocumentRoot &quot;/usr/share/puppet-dashboard/public/&quot; ErrorLog /var/log/httpd/puppet-dashboard_error.log LogLevel warn CustomLog /var/log/httpd/puppet-dashboard_access.log combined &lt;/VirtualHost&gt; 让 Dashboard 使用 Reports $ vi /etc/puppet/puppet.conf [master] reports = store, http reporturl = http://bigdata.xxxx.com:80/reports/upload 重启 puppetmaster 服务 $ /etc/init.d/puppetmaster restart 导入报告 $ cd /usr/share/puppet-dashboard $ rake RAILS_ENV=production reports:import 执行导入的 reports $ rake jobs:work RAILS_ENV=&quot;production&quot; 下载及文档地址 http://code.google.com/p/puppet-manifest-share/downloads/list http://www.vpsee.com/2012/03/install-puppet-on-centos-6-2/ http://dongxicheng.org/cluster-managemant/puppet/]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>puppet</tag>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Graphite 安装]]></title>
    <url>%2Fmonitor%2FGraphite%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[参考： http://www.jsxubar.info/category/system-administration/graphite/ http://www.jsxubar.info/category/system-administration/page/3/ 更多集成 grafana 及 Diamond 请看： http://dongweiming.github.io/blog/archives/shi-yong-grafanahe-diamondgou-jian-graphitejian-kong-xi-tong/ 使用 yum 安装环境 $ yum install bitmap bitmap-fonts Django pycairo python-devel python-ldap python-memcached mod_wsgi python-sqlite2 glibc-devel gcc gcc-c++ git openssl-devel python-zope-interface httpd memcached python-hashlib django-tagging python-twisted python-simplejson httpd mod_wsgi # 其它的使得 pip 安装就可以 $ pip install whisper $ pip install carbon $ pip install graphite-web 安装并升级为最新的 zope.interface 及 twisted # (确保这个版本要到 3.6.0 以上，如果不行，下载安装) 及 twisted $ wget https://pypi.python.org/simple/zope.interface/zope.interface-4.1.2-py2.6-win-amd64.egg $ easy_install zope.interface-4.1.2-py2.6-win-amd64.egg # test twisted [root@bigdata twisted]# python Python 2.6.6 (r266:84292, Jan 22 2014, 09:42:36) [GCC 4.4.7 20120313 (Red Hat 4.4.7-4)] on linux2 Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; from twisted.python.compat import _PY3 &gt;&gt;&gt; Check for missing dependencies $ python /tmp/pip-build-me/graphite-web/check-dependencies.py 设置权限 $ chown -R apache:apache /opt/graphite/storage/ 配置文件 $ cp /opt/graphite/webapp/graphite/local_settings.py.example /opt/graphite/webapp/graphite/local_settings.py $ cp /opt/graphite/conf/carbon.conf.example /opt/graphite/conf/carbon.conf $ cp /opt/graphite/conf/storage-schemas.conf.example /opt/graphite/conf/storage-schemas.conf 同步数据库 # 如果需要用其它数据库，请修改 /opt/graphite/webapp/graphite/local_settings.py $ python /opt/graphite/webapp/graphite/manage.py syncdb $ cd /opt/graphite/conf/ $ cp graphite.wsgi.example graphite.wsgi $ cp storage-schemas.conf.example storage-schemas.conf $ cp carbon.conf.example carbon.conf $ cd /opt/graphite/webapp/graphite $ cp local_settings.py.example local_settings.py 在 httpd 中启用 virtualHost $ cd ../../ $ cp examples/example-graphite-vhost.conf /etc/httpd/conf.d/vhost-graphite.conf # 并修改 $ vi /etc/httpd/conf.d/vhost-graphite.conf WSGISocketPrefix /var/run/httpd/wsgi 修改已知的 bug $ vi /opt/graphite/webapp/graphite/storage.py def fetch(self, startTime, endTime, now=None): return whisper.fetch(self.fs_path, startTime, endTime) # 去掉最后一个 now 替换 graphite 的界面 graph-index-master graphite-web-master]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>graphite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GlusterFS 安装]]></title>
    <url>%2Fstorage%2FGlusterFS%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[参考： https://wiki.centos.org/zh/HowTos/GlusterFSonCentOS $ wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/EPEL.repo/glusterfs-epel.repo 安装软件 yum install glusterfs{,-fuse,-server} yum install glusterfs-geo-replication.x86_64 如遇到以下错误： Transaction check error: file /usr/lib/systemd/system/blk-availability.service from install of device-mapper-7:1.02.107-5.el7_2.2.x86_64 conflicts with file from package lvm2-7:2.02.105-14.el7.x86_64 file /usr/sbin/blkdeactivate from install of device-mapper-7:1.02.107-5.el7_2.2.x86_64 conflicts with file from package lvm2-7:2.02.105-14.el7.x86_64 file /usr/share/man/man8/blkdeactivate.8.gz from install of device-mapper-7:1.02.107-5.el7_2.2.x86_64 conflicts with file from package lvm2-7:2.02.105-14.el7.x86_64 # 删除 lvm2 $ rpm -e lvm2 挂载分区及配置防火墙 # mkdir $ mkdir /export/brick1 # 这里可以修改权限 , 其它程序可以使用， 注意所有服务器上都要修改！！！ $ chmod 777 /export/brick1 # firewall $ firewall-cmd --zone=public --add-port=24007-24008/tcp --permanent $ firewall-cmd --zone=public --add-service=nfs --add-service=samba --add-service=samba-client --permanent $ firewall-cmd --zone=public --add-port=111/tcp --add-port=139/tcp --add-port=445/tcp --add-port=965/tcp --add-port=2049/tcp \ --add-port=38465-38469/tcp --add-port=631/tcp --add-port=111/udp --add-port=963/udp --add-port=49152-49251/tcp --permanent $ firewall-cmd --reload 启动 glusterd 服务 $ service glusterd start # if centos7: $ systemctl enable glusterd $ systemctl start glusterd $ systemctl status glusterd # from server1 $ gluster peer probe SERVER2 # from server2 $ gluster peer probe SERVER1 # check peer $ gluster peer status $ gluster volume create gv0 replica 2 HOSTNAME_OF_SERVER1:/export/brick1/gv0 HOSTNAME_OF_SERVER2:/export/brick1/gv0 $ gluster volume start gv0 $ gluster volume info $ gluster volume status # How to remove a volume or peer # stop Volume $ gluster volume stop gv0 # delete Volume $ gluster volume delete gv0 $ gluster peer detach NAME_OF_PEERNODE Test Gluster volume # mount to /mnt $ mount -t glusterfs node01.yourdomain.net:/gv0 /mnt $ vi /etc/fstab gluster1.example.com:/gv0 /mnt/glusterfs glusterfs defaults,_netdev 0 0 # 如果使用 nfs 协议使用 # GlusterFS NFS 服务器只支持第 3 版的 NFS 沟通协议。 $ vi /etc/nfsmount.conf Defaultvers=3 $ systemctl restart glusterd.service # start force $ gluster volume set gv0 nfs.disable off $ gluster volume start gv0 force $ mount -t nfs PEER_NODE:/gv0 /mnt/glusterfs 配置 Quorum() ...... 参考 : https://wiki.centos.org/zh/HowTos/GlusterFSonCentOS]]></content>
      <categories>
        <category>storage</category>
      </categories>
      <tags>
        <tag>gluster</tag>
        <tag>dfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP 高级配置]]></title>
    <url>%2Flinux%2FDHCP%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[# 一、DHCP 中继代理配置 # (在其它服务上安装 dhcpd 软件)： $ vi /etc/sysconfig/dhcrelay # Command line options here INTERFACES=&quot;eth1 eth2&quot; DHCPSERVERS=&quot;192.168.1.1&quot; # 也可以通过以下命令方式来实现： $ dhcrelay -i eth1 -i eth2 192.168.1.1 # Linux DHCP 配置完成后，重新启动 DHCP 服务。 # 二、DHCP 超网配置 ddns-update-style interim; /*dhcp 支持的 dns 动态更新方式 */ ignore client-updates; /* 忽略客户端 DNS 动态更新 */ shared-network mynet { /* 超网作用域选项，共同部分 */ option subnet-mask 255.255.255.0; /* 子网掩码 */ option domain-name &quot;koumm.net&quot;; /* 域名 */ option domain-name-servers 192.168.1.2; /*dns IP*/ option broadcast-address 192.168.1.255; /* 广播地址 */ default-lease-time 86400; /* 租期 1 天，秒数 */ max-lease-time 172800; /* 最长租期 2 天 */ subnet 192.168.1.0 netmask 255.255.255.0 { /*1.0 子网段 */ range 192.168.1.11 192.168.1.100; /*ip 地址段范围 */ option routers 192.168.1.1; /* 网关地址 */ /* 绑定 pc1 主机 ip 地址配置 */ host pc1 { hardware ethernet 00:a0:cc:cf:9C:14; fixed-address 192.168.1.20; } /* 绑定 pc2 主机 ip 地址配置 */ host pc2 { hardware ethernet 04:20:c1:f8:37:11; fixed-address 192.168.1.30; } } subnet 192.168.2.0 netmask 255.255.255.0 { /*2.0 子网段 */ range 192.168.2.10 192.168.2.100; /*ip 地址段范围 */ option routers 192.168.2.1; /* 网关地址 */ } subnet 192.168.3.0 netmask 255.255.255.0 { /*3.0 子网段 */ range 192.168.3.10 192.168.3.100; /*ip 地址段范围 */ option routers 192.168.3.1; /* 网关地址 */ } }]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>dhcp</tag>
        <tag>pxe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gearman 安装]]></title>
    <url>%2Fcluster%2FGearman%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[参考 http://www.php-oa.com/2010/09/05/perl-gearman-distributed.html python gearman library home page http://samuelks.com/python-gearman/docs/ Tim Yang：利用 Gearman 来实现远程监控与管理 http://timyang.net/linux/gearman-monitor/ # 一、安装 grarmand 及 libgearman-devel $ yum install gearmand libgearman-devel php-pecl-gearman (直接安装这个 php-pecl-gearman 就不用第二步：安装 PHP 的 API 了) # 二、安装 PHP 的 API $ yum install php php-devel boost boost-devel libuuid libuuid-devel $ tar -xzf gearman-1.1.2.tgz # 下载地址：https://pecl.php.net/package/gearman $ cd gearman-1.1.2 $ phpize $ ./configure; make; make install // 实际上是给 PHP 增加了个 gearman 的 extension: /usr/lib64/php/modules/gearman.so # 增加 php 扩展 $ vi /etc/php.d/gearman.ini ; Enable gearman extension module extension=gearman.so # 三、启动 gearmand # (如果使用默认参数，需要开启 IPV6) # 可以设置成服务启动： $ vi /etc/sysconfig/gearmand OPTIONS=“-L 0.0.0.0 –verbose=DEBUG” –&gt; 根据自己需求设置 –verbose $ service gearmand start $ gearmand -d –http-port 8090 -L 0.0.0.0 -p 4730 # 如果需要使用数据库 gearmand -d –http-port=8080 -L 0.0.0.0 -p 4730 –mysql-user=root –mysql-password=YOUR_PASS –mysql-db gearman $ gearman -w -f wc – wc -l // 开启一个 worker（-w）, 监听一个函数 wc(-f wc)， 函数的内容为 wc -l # 将 /etc/passwd 文件给函数 wc 进行处理 $ gearman -f wc &lt; /etc/passwd $ gearadmin –show-jobs –status –workers – … ## 1. Worker: addServer(); $worker-&gt;addFunction(“reverse”, “reverse_fn”); while (1) {print “Waiting for job…”; $ret = \(worker-&gt;work(); if(\)worker-&gt;returnCode() != GEARMAN_SUCCESS) {break;} } function reverse_fn(GearmanJob $job) {$workload = $job-&gt;workload(); echo “Received job:”. $job-&gt;handle(). “”; echo “Workload: $workload”; \(result = strrev(\)workload); echo “Result: $result”; return $result; } ?&gt; ## 2. client: addServer(); echo “sending job”; if($result) {echo “Success: $result”;} else {echo “Failed!”;} ?&gt;]]></content>
      <categories>
        <category>cluster</category>
      </categories>
      <tags>
        <tag>gearman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斐讯 K2 路由器刷机]]></title>
    <url>%2Flinux%2F%E6%96%90%E8%AE%AFK2%E8%B7%AF%E7%94%B1%E5%99%A8%E5%88%B7%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[买个 SS 帐号 不要问我 SS 是什么，我只能告诉你它是现在最好的 fun 墙工具！一般 400 左右一年，但每个商家质量千差万别，买前最好问清楚有没有流量限制，可以用几台客户端等，最好有老司机带路。 路由刷机 路由器通电，网线一端连接 &quot; 自己电脑的网口 “，一头连接路由器的”LAN&quot; 口， 注意：不是 WAN 口 查看自己电脑的 &quot; 网络连接 “，选中” 本地连接 “，点击右键，选择” 状态 &quot; -&gt; &quot; 详细信息 &quot; 查看自己的 IP 地址 自己电脑中打开浏览器：http://192.168.1.1 (一般是 192.168.1.1 这个 IP 地址，IP 前三位和 &quot; 本地连接 &quot; 中看到的 IP 一致，但最后一位修改为 1) 用户名和密码默认 “admin/admin” 登陆 WEB 后，点击菜单 &quot; 系统 &quot; -&gt; &quot; 升级 “(其实我们是先降级，因为斐讯的默认系统是不让刷机的)。然后浏览本地”breed_k2_163_v17_breed.bin&quot; 文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>刷机</tag>
        <tag>斐讯 K2</tag>
        <tag>翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编码与文件格式转换]]></title>
    <url>%2Flinux%2F%E7%BC%96%E7%A0%81%E4%B8%8E%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[作用 在 windows 下使用 hexo 时，经常会出现 GBK 编码与 DOS 的问题 Windows 下自动将博客发布到 github 编码转换 “Trans_To_UTF-8.py” 12345678910111213141516171819202122232425262728# 请把以下脚本放至 /usr/local/bin/ 目录下 import os,sysdef convert(filename, in_enc = "GBK", out_enc="UTF8" ): try: print "convert" + filename, content = open(filename).read() new_content = content.decode(in_enc).encode(out_enc) open(filename, 'w').write(new_content) print "done" except: print "error"def explore(dir): for root, dirs, files in os.walk(dir): for file in files: path = os.path.join(root, file) convert(path)def main(): for path in sys.argv[1:]: if os.path.isfile(path): convert(path) elif os.path.isdir(path): explore(path)if __name__ == "__main__": main() 准备脚本 “prepare.sh” 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667POST_DIR="/cygdrive/e/blog/source/_posts"FBS_ESC=`echo -en "\033"`COLOR_RED="$&#123;FBS_ESC&#125;[1;31m" # ErrorCOLOR_GREEN="$&#123;FBS_ESC&#125;[1;32m"; # SuccessCOLOR_YELLOW="$&#123;FBS_ESC&#125;[1;33m" # WarningCOLOR_CLOSE="$&#123;FBS_ESC&#125;[0m" # Closecd $POST_DIRfor i in *; do if grep -q "author: dongcj &lt;ntwk@163.com&gt;" $i; then echo "$&#123;COLOR_GREEN&#125;SKIP$&#123;COLOR_CLOSE&#125;: filename: $i..." continue fi if file $i | grep -q "CRLF"; then # change to unix echo -n "$&#123;COLOR_YELLOW&#125;WARN$&#123;COLOR_CLOSE&#125;: filename: $i, coverting to unix.." dos2unix $i &amp;&amp; echo "done" || echo "$&#123;COLOR_RED&#125;failed$&#123;COLOR_CLOSE&#125;" fi if ! file $i | grep -q "UTF-8"; then # change to UTF-8 python /usr/local/bin/Trans_To_UTF-8.py $i &amp;&amp; echo "done" || echo "$&#123;COLOR_RED&#125;failed$&#123;COLOR_CLOSE&#125;" fi if ! ls $i | grep -q "\.md$"; then echo -n "$&#123;COLOR_YELLOW&#125;WARN$&#123;COLOR_CLOSE&#125;: filename: $i, renaming to $&#123;i%.*&#125;.md.." # rename suffix to ".md" mv $i $&#123;i%.*&#125;.md &amp;&amp; echo "done" || echo "$&#123;COLOR_RED&#125;failed$&#123;COLOR_CLOSE&#125;" else echo "filename: $i, skipped rename~" fi no_suffix_filename="$&#123;i%.*&#125;" # if does not have title if ! grep -q "title:" $i; then echo -n "$&#123;COLOR_YELLOW&#125;WARN$&#123;COLOR_CLOSE&#125;: filename: $i, adding title.." sed -i "1s/^/---\ntitle: $no_suffix_filename\n---\n/" $i echo "done" fi # zero title content title_content=`sed -n '/title: /p' $i | awk -F':' '&#123;print $NF&#125;' | xargs` if [-z "$title_content" ]; then # update title when it is NULL echo -n "$&#123;COLOR_YELLOW&#125;WARN$&#123;COLOR_CLOSE&#125;: filename: $i, updating title.." sed -i "s/title: .*/title: $no_suffix_filename/" $i echo "done" else echo "filename: $i, skipped update~" fi # add author info if ! grep -q "author: dongcj &lt;ntwk@163.com&gt;" $i; then echo -n "$&#123;COLOR_YELLOW&#125;WARN$&#123;COLOR_CLOSE&#125;: filename: $i, updating author.." sed -i '/title: /a author: dongcj &lt;ntwk@163.com&gt;' $i echo "done" fi echodone Windows 下 &quot; 更新博客 .bat&quot; 12345REMcd "/cygdriver/d/blog"D:hexo g &amp;&amp; hexo decho "success"]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>utf-8</tag>
        <tag>编码</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装源_RedHat,CentOS 备用源]]></title>
    <url>%2Flinux%2FRedHat%E3%80%81CentOS%E5%9B%BD%E5%86%85%E5%A4%87%E7%94%A8%E5%AE%89%E8%A3%85%E6%BA%90%2F</url>
    <content type="text"><![CDATA[yum 更新 12345yum search fastestmirroryum install yum-fastestmirror* -yyum update yum*yum update kernel*yum update # (将链接中的 &quot;X&quot; 换为 7/6/5 即可下载不同版本的 repo) rpm -Uhv http://pkgs.repoforge.org/rpmforge-release/rpmforge-release-0.5.3-1.el&lt;X&gt;.rf.x86_64.rpm rpm -Uhv http://pkgs.repoforge.org/rpmforge-release/rpmforge-release-0.5.3-1.el&lt;X&gt;.rf.i686.rpm epel 源 (elrepo.org) yum install epel-release elrepo(update kernel) rpm -Uvh http://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm # (将链接中的 &quot;X&quot; 换为 7/6/5 即可下载不同版本的 repo) rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm # redhat/centos 6 rpm -Uvh http://download1.rpmfusion.org/free/el/updates/6/x86_64/rpmfusion-free-release-6-1.noarch.rpm rpm -Uvh http://download1.rpmfusion.org/free/el/updates/6/i386/rpmfusion-free-release-6-1.noarch.rpm rpm -Uvh http://download1.rpmfusion.org/nonfree/el/updates/6/i386/rpmfusion-nonfree-release-6-1.noarch.rpm # redhat/centos 7 only have x86_64 packages rpm -Uvh http://download1.rpmfusion.org/free/el/updates/7/x86_64/r/rpmfusion-free-release-7-1.noarch.rpm CentOS 中国科学技术大学 USTC mirror(每小时更新一次) 地址：http://centos.ustc.edu.cn/ cd /etc/yum.repos.d mv CentOS-Base.repo CentOS-Base.repo.save-`date +%F` centos 7 1234567891011121314151617181920212223242526272829303132vi USTC.repo[base]name=CentOS-$releasever - Base#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-$releasever - Updates# mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updatesbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-$releasever - Extras# mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extrasbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plus# mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplusbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 centos 6 12345678910111213141516171819202122232425262728293031323334353637383940[base]name=CentOS-$releasever - Base - mirrors.ustc.edu.cnbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/os/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=1gpgkey=https://mirrors.ustc.edu.cn/centos/RPM-GPG-KEY-CentOS-6#released updates[updates]name=CentOS-$releasever - Updates - mirrors.ustc.edu.cnbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/updates/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updatesgpgcheck=1gpgkey=https://mirrors.ustc.edu.cn/centos/RPM-GPG-KEY-CentOS-6#additional packages that may be useful[extras]name=CentOS-$releasever - Extras - mirrors.ustc.edu.cnbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/extras/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extrasgpgcheck=1gpgkey=https://mirrors.ustc.edu.cn/centos/RPM-GPG-KEY-CentOS-6#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plus - mirrors.ustc.edu.cnbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/centosplus/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplusgpgcheck=1enabled=0gpgkey=https://mirrors.ustc.edu.cn/centos/RPM-GPG-KEY-CentOS-6#contrib - packages by Centos Users[contrib]name=CentOS-$releasever - Contrib - mirrors.ustc.edu.cnbaseurl=https://mirrors.ustc.edu.cn/centos/$releasever/contrib/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=contribgpgcheck=1enabled=0gpgkey=https://mirrors.ustc.edu.cn/centos/RPM-GPG-KEY-CentOS-6 网易开源镜像站 地址：http://mirrors.163.com/.help/centos.html 12345678910cd /etc/yum.repos.d# centos6wget http://mirrors.163.com/.help/CentOS6-Base-163.repo# centos7wget http://mirrors.163.com/.help/CentOS7-Base-163.repo# 生成缓存 yum makecache # 删除 32 位组件： yum remove \*.i\?86 # 编辑 /etc/yum.conf 并加入以下一行： exclude = *.i?86]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>yum rpmforge</tag>
        <tag>国内源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dnsmasq 使用本地 Hosts 配置提供 DNS 服务]]></title>
    <url>%2Flinux%2Fdns%2FDnsmasq%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0host%E4%B8%BADNS%2F</url>
    <content type="text"><![CDATA[1. 使用 dnsmasq 提供外网 dns 服务 $ apt-get install dnsmasq 1.1. 修改 dnsmasq 主配置文件 12345# 将以下文本添加到 /etc/dnsmasq.conf 文件的最后：listen-address=127.0.0.1,OUTER_IP # 这里如果使用 0.0.0.0 会失败 addn-hosts=/etc/hosts # 直接解析本地的 hostsresolv-file=/etc/resolv.dnsmasq.conf # 可以增加本机的 dns 服务 (/etc/resolv.conf 里最多只生效三个)conf-dir=/etc/dnsmasq.d # 该目录下的所有文件都会解析 1.2. 生成域名映射 12345# 在 /etc/dnsmasq.d/ 目录下新建一个文件，随意起个名字 vi /etc/dnsmasq.d/dns.conf# 指定你要映射的域名，例如 google.com，则将下面贴进 dns.conf 文件 address="/google.com/172.17.0.4" 1.3. 启动服务 /etc/init.d/dnsmasq start 1.4. 测试 dig google.com @OUTER_IP --&gt; 172.17.0.4 2. 本地 hosts 配合 NetworkManager 方式 12345678910$ cat /etc/NetworkManager/dnsmasq.d/hosts.confaddn-hosts=/etc/hosts$ sudo service networking restart$ sudo /etc/init.d/dns-clean restart# 修改后要求下面的几个命令输出相同的 IP 地址：$ host u1$ nslookup u1$ getent ahosts u1]]></content>
      <categories>
        <category>linux</category>
        <category>dns</category>
      </categories>
      <tags>
        <tag>dns dhcp</tag>
        <tag>dnsmasq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装 Easy_install 及 Pip]]></title>
    <url>%2Flinux%2Flinux%E5%AE%89%E8%A3%85easy_install%E5%8F%8Apip%2F</url>
    <content type="text"><![CDATA[需要先将 python2.6 升级至 2.7，请参见： python2.6 升级至 python2.7 安装 easy_install # 获取软件包 $ wget --no-check-certificate https://pypi.python.org/packages/source/s/setuptools/setuptools-3.6.tar.gz # 解压 : $ tar -xvf setuptools-3.6.tar.gz &amp;&amp; cd setuptools-3.6 # 使用 Python 2.7.x 安装 setuptools /usr/local/bin/python2.7 setup.py install 更多 easy_install 用法见： easy_install 用法 安装 PIP # 下载方法 1 $ curl https://bootstrap.pypa.io/get-pip.py | python - # 下载方法 2 $ wget https://bootstrap.pypa.io/get-pip.pyy -O - | python # 安装方法 1 $ yum install python-pip # 安装方法 2 $ /usr/local/bin/easy_install pip (建议 , 如果升级使用此方法！) # 升级 pip $ /usr/local/bin/easy_install --upgrade pip # 升级 distribute(distribute 是 setuptools 的替代方案，pip 是 easy_install 的替代方案) $ pip install -U distribute # 升级 ez_setup $ curl https://bootstrap.pypa.io/ez_setup.py | python - &gt; PIP 使用指定源，且不缓存到目录 $ pip install --no-cache-dir -r requirements.txt -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com &gt; 安装墙内 PIP http://realfavicongenerator.net/ easy_install 用法 # 1 直接安装： easy_install SQLObject # 2 使用下载页面地址安装 easy_install -f http://pythonpaste.org/package_index.html SQLObject # 3 直接给出下载 url 安装 easy_install http://example.com/path/to/MyPackage-1.2.3.tgz # 4 .egg 文件的安装 easy_install /my_downloads/OtherPackage-3.2.1-py2.3.egg # 5 跟新安装过的包 easy_install --upgrade PyProtocols # 6 安装已经下载和提取在当前目录下的包 easy_install . # 7 安装特定特定版本的库 easy_install &quot;SomePackage==2.0&quot; # 8 大于某个版本 easy_install &quot;SomePackage&gt;2.0 # 9 卸载库 easy_install -m PackageName]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>easy_install</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Autossh]]></title>
    <url>%2Flinux%2FAutossh%2F</url>
    <content type="text"><![CDATA[http://www.cnblogs.com/eshizhan/archive/2012/07/16/2592902.html 1.1. 设置到 /etc/rc.local 注意：使用 -f 参数需要先设置 ssh 信任关系 123#!/bin/shautossh -M 5678 -o "StrictHostKeyChecking no" -o "ServerAliveInterval 30" -o "ServerAliveCountMax 3" \ -fNR 8377:localhost:2018 root@console.svicloud.com -p46178 1.2. 设置运行权限，别 忘记 了 1chmod a+x /etc/rc.local]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Bind 安装配置]]></title>
    <url>%2Flinux%2FBind%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[参考： http://linux.vbird.org/linux_server/0350dns.php#server_settings DDNS 的安装见：http://wenku.baidu.com/view/31f263d233d4b14e8524687e.html 1. 安装 $ rpm -ivh bind bind-chroot 2. 配置 1. 生成 rndc key $ rndc-confgen -r /dev/random &gt;/etc/rndc.conf $ chown root:named /etc/rndc.conf 2. 配置 named.conf $ vi /etc/named.conf options { // Put files that named is allowed to write in the data/ directory: directory &quot;/var/named&quot;; // &quot;Working&quot; directory dump-file &quot;data/cache_dump.db&quot;; statistics-file &quot;data/named_stats.txt&quot;; memstatistics-file &quot;data/named_mem_stats.txt&quot;; allow-query {any;}; recursion yes; listen-on port 53 {any;}; allow-transfer {none;}; // 不允许别人进行 zone 转移 , 如果有 slave DNS，则可以开启 }; acl intranet {192.168.1.0/24;}; // 本地来源 IP acl internet {! 192.168.1.0/24; any;}; // 外部来源 IP. 惊叹号表示反向选择 view &quot;lan&quot; { // lan 只是一个名字而已，代表的是内网 match-clients {&quot;intranet&quot;;}; // 吻合的才使用底下的 zone zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;; }; zone &quot;xdol.vicp.net&quot; IN { type master; file &quot;named.xdol.vicp.net&quot;; }; zone &quot;1.168.192.in-addr.arpa&quot; IN { type master; file &quot;named.192.168.1&quot;; }; }; view &quot;wan&quot; {match-clients { &quot;internet&quot;;}; // 吻合的才使用底下的 zone zone &quot;.&quot; IN { type hint; file &quot;named.ca&quot;; }; zone &quot;xdol.vicp.net&quot; IN { type master; file &quot;named.xdol.vicp.net.inter&quot;; }; }; key &quot;rndc-key&quot; { // 这里是 rndc 的密钥，需要修改为 /etc/rndc.conf 中一样的 secret algorithm hmac-md5; secret &quot;wFLLOzcaq3T2CFNvbT3d7g==&quot;; }; controls { inet 127.0.0.1 port 953 allow {127.0.0.1;} keys {&quot;rndc-key&quot;;}; }; logging { // 防止外部服务器错误导致 log 记录 category lame-servers {null;}; }; 3. zone 配置 1. 正向 zone 内网配置 $ vi /var/named/named.xdol.vicp.net $TTL 600 @ IN SOA master.xdol.vicp.net. dongchaojun.gmail.com. (2012040702 3H 15M 1W 1D); @ IN NS master.xdol.vicp.net. ;DNS 服务器名称 master.xdol.vicp.net. IN A 192.168.1.109 ;DNS 服务器 IP @ IN MX 10 www.xdol.vicp.net. ; 邮件服务器 ; 关于 192.168.1.109 这部主机的正解设定 www.xdol.vicp.net. IN A 192.168.1.109 ; 内部网卡的 IP ftp.xdol.vicp.net. IN CNAME www.xdol.vicp.net. ssh.xdol.vicp.net. IN CNAME www.xdol.vicp.net. ; 其它主机的正确设定 client.xdol.vicp.net. IN A 192.168.1.246 2. 正向 zone 外网配置 $ vi /var/named/named.xdol.vicp.net.inter $TTL 600 @ IN SOA master.xdol.vicp.net. dongchaojun.gmail.com. (2012040702 3H 15M 1W 1D); @ IN NS master.xdol.vicp.net. ;DNS 服务器名称 master.xdol.vicp.net. IN A 11.11.11.11 ;DNS 服务器 IP @ IN MX 10 www.xdol.vicp.net. ; 邮件服务器 ; 关于 192.168.1.109 这部主机的正解设定 www.xdol.vicp.net. IN A 11.11.11.11 ; 外部网卡的 IP ftp.xdol.vicp.net. IN CNAME www.xdol.vicp.net. ssh.xdol.vicp.net IN CNAME www.xdol.vicp.net. ; 其它主机的正确设定 client.xdol.vicp.net. IN A 192.168.1.246 3. 反向 zone 内、外网设置 (外网不需要反向 zone) $ vi /var/named/named.192.168.1 $TTL 600 @ IN SOA master.xdol.vicp.net. dongchaojun.gmail.com. (2012040702 3H 15M 1W 1D) @ IN NS master.xdol.vicp.net. 109 IN PTR master.xdol.vicp.net. ; 将原来的 A 改为 PTR 标志而已 109 IN PTR www.xdol.vicp.net. 246 IN PTR client.xdol.vicp.net. 4. 启动服务 service named start chkconfig named on 5. 配置 DDNS(可选) 1. DNS 服务端生成主机端的 key(在当前目录下会生成一个公钥及一个私钥) dnssec-keygen -r /dev/urandom -a HMAC-MD5 -b 512 -n HOST greatwall 2. 将公钥加入到配置文件中 $ vi /etc/named.conf // 先在任意地方加入這個 Key 的相關密碼資訊！ (加而不是更新其它的) key &quot;greatwall&quot; { algorithm hmac-md5; secret &quot;xZmUo8ozG8f2OSg/cqH8Bqxk59Ho8....3s9IjUxpFB4Q==&quot;; // 这里换成算出的公钥 cat 出来的内容 }; // 然後將你原本的 zone 加入底下這一段宣示 zone &quot;centos.vbird&quot; IN { type master; file &quot;named.centos.vbird&quot;; update-policy { // 这个 update-policy 及后面就是添加的 grant greatwall name greatwall.xdol.vicp.net. A; }; }; $ chmod g+w /var/named $ chown named /var/named/named.centos.vbird $ /etc/init.d/named restart $ setsebool -P named_write_master_zones=1 // selinux 的 3. 客户端更新 将 ddns 的 key 传给客户端，并在客户端 crontab 中添加以下自动运行的脚本 #!/bin/bash # # Update your Dynamic IP by using BIND 9 &#39;s tools # ############################################### # History # 2004/10/27 VBird First time release # ############################################## PATH=/sbin:/bin:/usr/sbin:/usr/bin export PATH # 0. keyin your parameters basedir=&quot;/usr/local/ddns&quot; # working directory keyfile=&quot;$basedir&quot;/&quot;Kgreatwall.+157+60932.key&quot; # your ddns&#39; key (filename) ttl=600 # the ttl time (10 min.) outif=&quot;eth0&quot; # Your interface (connect to internet) hostname=&quot;greatwall.xdol.vicp.net&quot; # Your hostname servername=&quot;192.168.1.109&quot; # The update primary DNS server name (or IP) showmesg=no # if yes then show messages # Get your new IP newip=`ifconfig &quot;$outif&quot; | grep &#39;inet addr&#39; | \ awk &#39;{print $2}&#39; | sed -e &quot;s/addr\://&quot;` checkip=`echo $newip | grep &quot;^[0-9]&quot;` if [&quot;$checkip&quot; == &quot;&quot;]; then echo &quot;$0: The interface can&#39;t connect internet....&quot; exit 1 fi # check if the DNS is the same with your IP dnsip=`host $hostname | head -n 1 | awk &#39;{print $4}&#39;` if [&quot;$newip&quot; == &quot;$dnsip&quot;]; then if [&quot;$showmesg&quot; == &quot;yes&quot;]; then echo &quot;$0: The IP is the same with DNS, Don&#39;t change it.&quot; fi exit 0 fi # create the temporal file tmpfile=$basedir/ns_auto_update.txt cd $basedir echo &quot;server $servername&quot; &gt; $tmpfile echo &quot;update delete $hostname A &quot; &gt;&gt; $tmpfile echo &quot;update add $hostname $ttl A $newip&quot; &gt;&gt; $tmpfile echo &quot;send&quot; &gt;&gt; $tmpfile # send yo 6. 附录： 名词解释 TLD: Top Level Domain ccTLD: Country code TLD TTL: Time to live 申請 DNS 領域查詢授權 NS 记录： NameServer A 记录： Address MX 记录： Mail CNAME 實際代表這個主機別名的主機名字 SOA：就是開始驗證 (Start of Authority) 的縮寫 PTR：就是指向 (PoinTeR) 的縮寫，後面記錄的資料就是反解到主機名稱囉！ 記錄 . 的 zone 的類型，就被我們稱為 hint 類型 因為使用 DHCP 時，系統會主動的使用 DHCP 伺服器傳來的資料進行系統設定檔的修訂。因此，你必須告知系統，不要使用 DHCP 傳來的伺服器設定值。 此時，你得要在 /etc/sysconfig/network-scripts/ifcfg-eth0 等相關檔案內，增加一行：『PEERDNS=no』，然後重新啟動網路即可。 在 domain 的部分，若可能的話，請盡量使用 FQDN，亦即是主機名稱結尾加上一個小數點 SOA 主要是與領域有關，所以前面當然要寫 ksu.edu.tw 這個領域名。而 SOA 後面共會接七個參數，這七個參數的意義依序是： 1.Master DNS 伺服器主機名稱：這個領域主要是哪部 DNS 作為 master 的意思。在本例中， dns1.ksu.edu.tw 為 ksu.edu.tw 這個領域的主要 DNS 伺服器囉； 管理員的 email：那麼管理員的 email 為何？發生問題可以聯絡這個管理員。要注意的是， 由於 @ 在資料庫檔案中是有特別意義的，因此這裡就將 abuse@mail.ksu.edu.tw 改寫成 abuse.mail.ksu.edu.tw ，這樣看的懂了嗎？ 序號 (Serial)：這個序號代表的是這個資料庫檔案的新舊，序號越大代表越新。 當 slave 要判斷是否主動下載新的資料庫時，就以序號是否比 slave 上的還要新來判斷，若是則下載，若不是則不下載。 所以當你修訂了資料庫內容時，記得要將這個數值放大才行！ 為了方便使用者記憶，通常序號都會使用日期格式『YYYYMMDDNU』來記憶，例如崑山科大的 2010080369 序號代表 2010/08/03 當天的第 69 次更新的感覺。不過，序號不可大於 2 的 32 次方，亦即必須小於 4294967296 才行喔。 更新頻率 (Refresh)：那麼啥時 slave 會去向 master 要求資料更新的判斷？ 就是這個數值定義的。崑山科大的 DNS 設定每 1800 秒進行一次 slave 向 master 要求資料更新。那每次 slave 去更新時， 如果發現序號沒有比較大，那就不會下載資料庫檔案。 失敗重新嘗試時間 (Retry)：如果因為某些因素，導致 slave 無法對 master 達成連線， 那麼在多久的時間內，slave 會嘗試重新連線到 master。在崑山科大的設定中，900 秒會重新嘗試一次。意思是說，每 1800 秒 slave 會主動向 master 連線，但如果該次連線沒有成功，那接下來嘗試連線的時間會變成 900 秒。若後來有成功，則又會恢復到 1800 秒才再一次連線。 失效時間 (Expire)：如果一直失敗嘗試時間，持續連線到達這個設定值時限， 那麼 slave 將不再繼續嘗試連線，並且嘗試刪除這份下載的 zone file 資訊。崑山科大設定為 604800 秒。意思是說，當連線一直失敗，每 900 秒嘗試到達 604800 秒後，崑山科大的 slave 將不再更新，只能等待系統管理員的處理。 快取時間 (Minumum TTL)：如果這個資料庫 zone file 中，每筆 RR 記錄都沒有寫到 TTL 快取時間的話，那麼就以這個 SOA 的設定值為主。 除了 Serial 不可以超過 2 的 32 次方之外，有沒有其它的限制啊針對這幾個數值？是有的，基本上就是這樣： Refresh &gt;= Retry *2 Refresh + Retry &lt; Expire Expire &gt;= Rrtry * 10 Expire &gt;= 7Days 一般來說，如果 DNS RR 資料變更情況頻繁的，那麼上述的相關數值可以訂定的小一些，如果 DNS RR 是很穩定的， 為了節省頻寬，則可以將 Refresh 設定的較大一些。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bind</tag>
        <tag>dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Systemd,systemctl 命令]]></title>
    <url>%2Flinux%2Fsystemd%E3%80%81systemctl%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[参考：http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html 本地电脑中有一份模板： frpc.service 可参考 1. Systemd 和 Systemctl 基础命令 1.1. 几个常用的服务控制 12345678910111213141516171819# 类似 chkconfig# type = [service | target | mount | socket | slice | scope | timer | path]systemctl list-unit-files [--type=TYPE ] [--state=STATE] | grep "SERVICE_NAME"# 列出启动失败单元systemctl --failed# 查看配置 | 环境systemctl &lt;cat | show&gt; SERVICE_NAME# Systemd 几个目录find /&#123;etc,usr/lib,run&#125;/systemd/ -name "*SERVICE_NAME*"# 删除服务systemctl stop SERVICE_NAMEsystemctl disable SERVICE_NAMErm -rf /&#123;etc,usr/lib,run&#125;/systemd/system/SERVICE_NAMEsystemctl daemon-reloadsystemctl reset-failed 1.2. 控制服务启动环境 使用 指定 的 EnvironmentFile： vi /lib/systemd/system/docker.service 12345678910[Service]Type=notifyNotifyAccess=allEnvironmentFile=-/run/containers/registries.confEnvironmentFile=-/etc/sysconfig/dockerEnvironmentFile=-/etc/sysconfig/docker-storageEnvironmentFile=-/etc/sysconfig/docker-networkEnvironment=GOTRACEBACK=crashEnvironment=DOCKER_HTTP_HOST_COMPAT=1Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin 使用 默认 目录中的 EnvironmentFile： vi /lib/systemd/system/docker.service.d/docker-options.conf 12[Service]Environment="DOCKER_OPTS=--insecure-registry=10.254.0.0/16 --graph=/opt/docker --registry-mirror=http://b438f72b.m.daocloud.io --iptables=false" 1.3. 如何屏蔽（让它不能启动）或显示服务（如 httpd.service） 1234567# 注意：这是一个演示如何增加一个服务systemctl mask httpd.serviceln -s '/dev/null' '/etc/systemd/system/httpd.service'# 删除服务systemctl unmask httpd.servicerm '/etc/systemd/system/httpd.service' 1.4. 其它 1234567891011121314151617181920212223242526272829303132333435## 分析 systemd 启动进程总时间systemd-analyze Startup finished in 487ms (kernel) + 2.776s (initrd) + 20.229s (userspace) = 23.493s# 分析启动时各个进程花费的时间systemd-analyze blame 8.565s mariadb.service 7.991s webmin.service 6.095s postfix.service 4.311s httpd.service ....## 服务关键链列表$ systemd-analyze critical-chain httpd.service The time after the unit is active or started is printed after the "@" character. The time the unit takes to start is printed after the "+" character. httpd.service +142ms └─network.target @11.168s └─network.service @9.456s +1.712s └─NetworkManager.service @8.858s +596ms └─firewalld.service @4.931s +3.926s └─basic.target @4.916s └─sockets.target @4.916s # 服务依赖性列表$ systemctl list-dependencies httpd.service httpd.service ├─system.slice └─basic.target ├─firewalld.service .... 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061## 按等级列出控制组systemd-cgls ├─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 23 ├─user.slice │ └─user-0.slice │ └─session-1.scope## 按 CPU、内存、输入和输出列出控制组 [root@manage ~]# systemd-cgtop Path Tasks %CPU Memory Input/s Output/s / 83 1.0 437.8M - - /system.slice - 0.1 - - - /system.slice/mariadb.service 2 0.1 - - - /system.slice/tuned.service 1 0.0 - - - /system.slice/httpd.service 6 0.0 - - - /system.slice/NetworkManager.service 1 - - - - /system.slice/atop.service 1 - - - - /system.slice/atopacct.service 1 - - - - /system.slice/auditd.service 1 - - - -## CPU 份额systemctl show -p CPUShares httpd.service# 各个服务的默认 CPU 分配份额 =1024，你可以增加 / 减少某个进程的 CPU 分配份额。systemctl set-property httpd.service CPUShares=2000systemctl show -p CPUShares httpd.service CPUShares=2000# 当你为某个服务设置 CPUShares，会自动创建一个以服务名命名的目录（如 httpd.service），# 里面包含了一个名为 90-CPUShares.conf 的文件，该文件含有 CPUShare 限制信息，你可以通过以下方式查看该文件：cat /etc/systemd/system/httpd.service.d/90-CPUShares.conf [Service] CPUShares=2000 ## 启动系统救援模式systemctl rescue Broadcast message from root@tecmint on pts/0 (Wed 2015-04-29 11:31:18 IST): The system is going down to rescue mode NOW!## 进入紧急模式systemctl emergency Welcome to emergency mode! After logging in, type "journalctl -xb" to view system logs, "systemctl reboot" to reboot, "systemctl default" to try again to boot into default mode.## 重启、停止、挂起、休眠系统或使系统进入混合睡眠systemctl rebootsystemctl haltsystemctl suspendsystemctl hibernatesystemctl hybrid-sleep]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>systemd</tag>
        <tag>systemctl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor 安装与配置]]></title>
    <url>%2Flinux%2FSupervisor%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装 12345678# 建议使用 yum 安装 yum install supervisor# 也可以使用 pip 安装 pip install supervisor# 生成配置文件 echo_supervisord_conf &gt;/etc/supervisord.conf 配置 生成的配置文件不用修改，直接在最后加下自己的配置，以下是样例 123456789101112131415[program:mysql]environment=API_UMBRELLA_CONFIG="/opt/api-umbrella/var/run/runtime_config.yml" # 可选 directory=/opt/api-umbrella/embedded/apps/web/current # 可选 command=service mysqld start # 必选，启动命令 autorestart=true # 必选，自动启动 redirect_stderr=true # 可选 stdout_syslog=true # 可选 [program:opsview]command=service opsview startautorestart=true[program:opsview-web]command=service opsview-web startautorestart=true 启动 $ service supervisord start &gt; 如果使用 pip 安装，需要自已写启动脚本 检查安装 # 如下即表示正常 supervisorctl status remote-launcher `RUNNING` pid 11087, uptime 9 days, 2:49:14]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Postgresql 安装]]></title>
    <url>%2Fdatabase%2FPostgresql%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装相关依赖库 $ yum -y install readline-devel zlib-devel make gcc gcc-c++ openldap openldap-devel \ openssl openssl-devel perl perl-devel perl-ExtUtils* python-devel tcl-devel pam-devel libxslt-devel $ yum -y install wget gcc systemtap systemtap-sdt-devel \ sgml-common docbook stylesheets openjade sgml-tools xsltproc \ libxml2 libxml2-devel bison flex libreadline6-devel 安装 12345678910111213141516# 配置用户、环境变量 $ useradd postgres$ vim /etc/profile export PATH=$PATH:$HOME/bin:/usr/local/pgsql/bin$ source /etc/profile$ wget https://ftp.postgresql.org/pub/source/v9.5.1/postgresql-9.5.1.tar.bz2$ bzcat postgresql-9.5.1.tar.bz2 | tar xBpf -$ cd postgresql-9.5.1$ ./configure --with-perl --with-python --with-tcl --with-openssl --without-ldap \ --with-libxml --with-libxslt --enable-thread-safety --with-wal-blocksize=64 \ --with-blocksize=32 --with-wal-segsize=64 -enable-dtrace --with-pam$ make &amp;&amp; make install 初始化数据库 123456789101112mkdir -p /pgdatachown postgres /pgdatasu - postgres/usr/local/pgsql/bin/initdb -D /pgdata/# 数据库参数修改 $ vim /pgdata/pg_hba.conf host all all 0.0.0.0/0 trust $ vim /pgdata/postgresql.conf listen_addresses = '*' max_connections = 1500 启动数据库 [快速] $ /usr/local/pgsql/bin/pg_ctl [-m fast] -D /pgdata/ -l ~/pg_logfile start 创建并导入库 12345su postgrespsqlpostgres=# create database &lt;DB_NAME&gt;;postgres=# \c &lt;DB_NAME&gt;;\i &lt;DB_FILE&gt;.sql]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>postgres</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 配置 Location 总结及 Rewrite 规则写法]]></title>
    <url>%2Fweb%2FNginx%E9%85%8D%E7%BD%AElocation%E6%80%BB%E7%BB%93%E5%8F%8Arewrite%E8%A7%84%E5%88%99%E5%86%99%E6%B3%95%2F</url>
    <content type="text"><![CDATA[location 正则写法 # 一个示例： location = / { # 精确匹配 / ，主机名后面不能带任何字符串 [configuration A] } location / { # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [configuration B] } location /documents/ { # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [configuration C] } location ~ /documents/Abc { # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [configuration CC] } location ^~ /images/ { # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [configuration D] } location ~* \.(gif|jpg|jpeg)$ { # 匹配所有以 gif,jpg 或 jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [configuration E] } location /images/ { # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [configuration F] } location /images/abc { # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F 与 G 的放置顺序是没有关系的 [configuration G] } location ~ /images/abc/ { # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [configuration H] } location ~* /js/.*/\.js ^~ 开头表示 uri 以某个常规字符串开头，不是正则匹配 开头表示区分大小写的正则匹配 ; ~* 开头表示不区分大小写的正则匹配 / 通用匹配 , 如果没有其它匹配 , 任何请求都会匹配到 你可以看到 任何以 /images/ 开头的都会匹配到 D 并停止，FG 写在这里是没有任何意义的，H 是永远轮不到的，这里只是为了说明匹配顺序 /documents/document.html -&gt; config C 匹配到 C，往下没有任何匹配，采用 C /documents/1.jpg -&gt; configuration E 匹配到 C，往下正则匹配到 E /documents/Abc.jpg -&gt; config CC 最长匹配到 C，往下正则顺序匹配到 CC，不会往下到 E 实际使用建议 所以实际使用中，个人觉得至少有三个匹配规则定义，如下： location = / {proxy_pass http://tomcat:8080/index} # 第二个必选规则是处理静态文件请求，这是 nginx 作为 http 服务器的强项 # 有两种配置模式，目录匹配或后缀匹配 , 任选其一或搭配使用 location ^~ /static/ {root /webroot/static/;} location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ {root /webroot/res/;} # 非静态文件请求就默认是动态请求，自己根据实际把握 # 毕竟目前的一些框架的流行，带 .php,.jsp 后缀的情况很少了 location / {proxy_pass http://tomcat:8080/} 引用 &gt; http://tengine.taobao.org/book/chapter_02.html &gt; http://nginx.org/en/docs/http/ngx_http_rewrite_module.html Rewrite 规则 rewrite 功能就是，使用 nginx 提供的全局变量或自己设置的变量，结合正则表达式和标志位实现 url 重写以及重定向。rewrite 只能放在 server{},location{},if{} 中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;u=str 只对 /a/we/index.php 重写。语法 rewrite regex replacement [flag]; 执行 server 块的 rewrite 指令 执行 location 匹配 执行选定的 location 中的 rewrite 指令 last : 相当于 Apache 的 [L] 标记，表示完成 rewrite break : 停止执行当前虚拟主机的后续 rewrite 指令集 redirect : 返回 302 临时重定向，地址栏会显示跳转后的地址 permanent : 返回 301 永久重定向，地址栏会显示跳转后的地址 last 不终止重写后的 url 匹配，即新的 url 会再从 server 走一遍匹配流程，而 break 终止重写后的匹配 break 和 last 都能组织继续执行后面的 rewrite 指令 if 指令与全局变量 if 判断指令 语法为 if(condition){…}，对给定的条件 condition 进行判断。如果为真，大括号内的 rewrite 指令将被执行，if 条件 (conditon) 可以是如下任何内容： 当表达式只是一个变量时，如果值为空或任何以 0 开头的字符串都会当做 false 直接比较变量和内容时，使用 = 或 != ~ 正则表达式匹配，~* 不区分大小写的匹配，!~ 区分大小写的不匹配 -f 和 !-f 用来判断是否存在文件 -d 和 !-d 用来判断是否存在目录 -e 和 !-e 用来判断是否存在文件或目录 -x 和 !-x 用来判断文件是否可执行 例如： if ($http_user_agent ~ MSIE) {rewrite ^(.*)$ /msie/$1 break; } // 如果 UA 包含 &quot;MSIE&quot;，rewrite 请求到 /msid/ 目录下 if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) {set $id $1;} // 如果 cookie 匹配正则，设置变量 $id 等于正则引用部分 if ($request_method = POST) {return 405;} // 如果提交方法为 POST，则返回状态 405（Method not allowed）。return 不能返回 301,302 if ($slow) {limit_rate 10k;} // 限速，$slow 可以通过 set 指令设置 if (!-f $request_filename){ break; proxy_pass http://127.0.0.1; } // 如果请求的文件名不存在，则反向代理到 localhost 。这里的 break 也是停止 rewrite 检查 if ($args ~ post=140){rewrite ^ http://example.com/ permanent;} // 如果 query string 中包含 &quot;post=140&quot;，永久重定向到 example.com location ~* \.(gif|jpg|png|swf|flv)$ { valid_referers none blocked www.jefflei.com www.leizhenfang.com; if ($invalid_referer) {return 404;} // 防盗链 } 全局变量 下面是可以用作 if 判断的全局变量 $args ： # 这个变量等于请求行中的参数，同 $query_string $content_length ： 请求头中的 Content-length 字段。 $content_type ： 请求头中的 Content-Type 字段。 $document_root ： 当前请求在 root 指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端 agent 信息 $http_cookie ： 客户端 cookie 信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为 GET 或 POST。 $remote_addr ： 客户端的 IP 地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过 Auth Basic Module 验证的用户名。 $request_filename ： 当前请求的文件路径，由 root 或 alias 指令与 URI 请求生成。 $scheme ： HTTP 方法（如 http，https）。 $server_protocol ： 请求使用的协议，通常是 HTTP/1.0 或 HTTP/1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始 URI，不包含主机名，如：” /foo/bar.php?arg=baz ”。 例：http://localhost:88/test1/test2/test.php $host：localhost $server_port：88 $request_uri：http://localhost:88/test1/test2/test.php $document_uri：/test1/test2/test.php $document_root：/var/www/html $request_filename：/var/www/html/test1/test2/test.php 常用正则 . ： 匹配除换行符以外的任意字符 ? ： 重复 0 次或 1 次 + ： 重复 1 次或更多次 * ： 重复 0 次或更多次 \d ：匹配数字 ^ ： 匹配字符串的开始 $ ： 匹配字符串的介绍 {n} ： 重复 n 次 {n,} ： 重复 n 次或更多次 [c] ： 匹配单个字符 c [a-z] ： 匹配 a-z 小写字母的任意一个 小括号 () 之间匹配的内容，可以在后面通过 $1 来引用，$2 表示的是前面第二个 () 里的内容。正则里面容易让人困惑的是 \ 转义特殊字符。 rewrite 实例 例 1： http {# 定义 image 日志格式 log_format imagelog ‘[$time_local]’ $image_file ‘’ $image_type ‘’ $body_bytes_sent ‘’ $status; # 开启重写日志 rewrite_log on; server { root /home/www; location / { # 重写规则信息 error_log logs/rewrite.log notice; # 注意这里要用‘’单引号引起来，避免 {} rewrite &#39;^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\.(png|jpg|gif)$&#39; /data?file=$3.$4; # 注意不能在上面这条规则后面加上“ last ”参数，否则下面的 set 指令不会执行 set $image_file $3; set $image_type $4; } location /data { # 指定针对图片的日志格式，来分析图片类型和大小 access_log logs/images.log mian; root /data/images; # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个 url 里 try_files /$arg_file /image404.html; } location = /image404.html { # 图片不存在返回特定的信息 return 404 &quot;image not found\n&quot;; } } rewrite ^/images/(.*)_(\d+)x(\d+)\.(png|jpg|gif)$ /resizer/$1.$4?width=$2&amp;height=$3? last; http://www.nginx.cn/216.html http://www.ttlsa.com/nginx/nginx-rewriting-rules-guide/ 老僧系列 nginx 之 rewrite 规则快速上手 http://fantefei.blog.51cto.com/2229719/919431 来源： http://seanlook.com/2015/05/17/nginx-location-rewrite/]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>location</tag>
        <tag>rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 常用命令与使用]]></title>
    <url>%2Flinux%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[参考：http://www.jianshu.com/p/f7b5431418d2 猴子都能懂的 git 入门：https://backlog.com/git-tutorial/cn/intro/intro5_2.html 1. 常见问题 1.1. 使用 go 安装 git 项目时报错 1server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none 解决办法： 123456789# install curl-config commandapt install libcurl4-openssl-dev# get the ca file location, default is: /etc/ssl/certs/ca-certificates.crtcurl-config --ca# add github ssl cert to ca bundleecho -n | openssl s_client -showcerts -connect github.com:443 2&gt;/dev/null | \ sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' &gt;&gt; `curl-config --ca` 1.2. 使用 密码 / key 方式认证 123456789# 带密码 https 认证 git clone https://svicloud:4L0V5F9ju8aVrxDP@git.svicloud.com/svicloud/catalog-powercloud.git# start the ssh-agent in the backgroundeval "$(ssh-agent -s)" Agent pid 59566ssh-add ~/.ssh/id_rsa# 测试 ssh git@github.com 1.3. Windows 下 tortiseGit 重新弹出密码输入 12# 删除以下文件夹中的文件：%appdata%\..\Local\Microsoft\Credentials 1.4. Windows 下使用 Daemon 12# 运行简单的 git daemon 服务 git daemon --verbose --export-all --reuseaddr --base-path=/tmp/catalog-krrish 报错如图 1.3-1： 1SO_KEEPALIVE on socket: No such file or directory 图 1.3-1 解决方法： 1git remote set-head origin -a 1.5. 同一网站，多个不同的帐号使用 git key 切换 安装 Git 安装 TortoiseGit (Windows 下初学者推荐) 在安装时指定 ssh，而不是 plink vi ~/.ssh/config 12345678910111213141516171819202122##--------------------------------------------------------------------------# &lt;GIT_DOMAIN&gt;#--------------------------------------------------------------------------## git clone git@&lt;ID1&gt;.&lt;GIT_DOMAIN&gt;:&lt;GIT_USER1&gt;/&lt;GIT_REPO1&gt;.githost &lt;ID1&gt;.&lt;GIT_DOMAIN&gt; hostname &lt;GIT_DOMAIN&gt; Port 22 User &lt;GIT_USER&gt; IdentityFile ~/.ssh/&lt;GIT_DOMAIN&gt;-&lt;GIT_USER&gt;-id_rsa##--------------------------------------------------------------------------# &lt;GIT_DOMAIN&gt;#--------------------------------------------------------------------------## git clone git@&lt;ID2&gt;.&lt;GIT_DOMAIN&gt;:&lt;GIT_USER2&gt;/&lt;GIT_REPO2&gt;.githost &lt;ID2&gt;.&lt;GIT_DOMAIN&gt; hostname &lt;GIT_DOMAIN&gt; Port 22 User &lt;GIT_USER&gt; IdentityFile ~/.ssh/&lt;GIT_DOMAIN&gt;-&lt;GIT_USER&gt;-id_rsa 使用不同的 ssh 别名连接 Git (host 后面接的即为别名) ### 1.5.1. 取消 global 的 email git config –global –unset user.name git config –global –unset user.email ### 1.5.2. 设置项目级自己的 email git config user.email “xxxx@xx.com” git config user.name “suzie” ## 1.6. 清除 git 路径中的所有 .git 文件 find . -name “.git” | xargs rm -Rf 1.7. 打包下载 git 文件中目录 1git archive --remote=$&#123;GIT_REPO&#125; latest www | tar xvf - -C /tmp 1.7.1. 使用 ssh config http://memoryboxes.github.io/blog/2014/12/07/duo-ge-gitzhang-hao-zhi-jian-de-qie-huan/ vi ~/.ssh/config 123456# 在主机 lb.gogs.pro.svi.pub 上的 svicloud 用户 host svicloud.lb.gogs.pro.svi.pub hostname lb.gogs.pro.svi.pub Port 22 User svicloud IdentityFile ~/.ssh/id_rsa_first 1.8. clone the repo 1234567git config --global user.email "webuser@local.com" &amp;&amp; \git config --global user.name "webuser" &amp;&amp; \git config --global push.default simple &amp;&amp; \rm -rf /tmp/www &amp;&amp; \git archive --remote=$&#123;GIT_REPO&#125; latest www | tar xvf - -C /tmp &amp;&amp; \mv /tmp/www/* /var/www/html/ &amp;&amp; \chown -Rf nginx.nginx /var/www/html 1.9. use the special version in npm package.json 1234567891011121314#!/bin/bashCURR_COMMIT=$(git rev-parse HEAD);CURR_VERSION=$(node -e "console.log(require('./package.json').version);");VER_HASH=$(git rev-list -n 1 v$CURR_VERSION);# Don't want to redo version bumpif [$CURR_COMMIT == $VER_HASH ]then echo 'Already up to date' exitfinpm version patch;NEW_VERSION=$(node -e "console.log(require('./package.json').version);");echo $NEW_VERSION;git push origin head; 1.10. git dirty 和 tag 123456789101112131415161718#!/bin/bashif [-n "$(git status --porcelain --untracked-files=no)" ]; then DIRTY="-dirty"fiCOMMIT=$(git rev-parse --short HEAD)GIT_TAG=$(git tag -l --contains HEAD | head -n 1)if [[-z "$DIRTY" &amp;&amp; -n "$GIT_TAG" ]]; then VERSION=$GIT_TAGelse VERSION="$&#123;COMMIT&#125;$&#123;DIRTY&#125;"fiif [-z "$ARCH" ]; then ARCH=amd64fi 1.11. use the special verion of repo 12git clone https://github.com/poweradmin/poweradmin.git .git checkout 772946ad40c765fece19aafbefd04fa23745e8ec 2. 常用配置 2.1. 配置认证、支持中文 12345# 配置用户名和 emailgit config --global user.name "dongcj"git config --global user.email "ntwk@163.com"git config --global core.autocrlf truegit config --list 2.2. 重新设置 git url 或 新增远程仓库 12345# 重新设置远程仓库地址 git remote set-url origin git@github.com:dongcj/blog.git# 提交到多个远程仓库 git remote add origin git@github.com:dongcj/blog.git 3. git 日常用法 123456789git status # 查看当前版本状态（是否修改）git ls-files # 列出 git index 包含的文件 git add xyz # 添加 xyz 文件至 indexgit add . # 增加当前子目录下所有更改过的文件至 indexgit commit -m 'xxx' # 提交 git commit --amend -m 'xxx' # ` 合并 ` 上一次提交（用于反复修改）git commit -am 'xxx' # 将 add 和 commit 合为一步 git rm xxx # 删除 index 中的文件 git rm -r * # 递归删除 3.1. git log 1234567891011git log # 显示提交日志 git log -1 # 显示 1 行日志 -n 为 n 行 git log -p test.html # 显示 test.html 的变更日志 git log --stat # 显示提交日志及相关变动文件 git log -p -m # 显示每个文件修改记录 git log v2.0 # 显示 v2.0 的日志 git log --pretty=format:'%h %s' --graph # 图示提交日志 git reflog # 显示所有提交，包括孤立节点 # 显示最近 20 条提交记录 git --no-pager log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr [%an])%Creset' --abbrev-commit --date=relative -20 更多格式化输出 : https://ruby-china.org/topics/939 3.2. git show 1234567891011git show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交修改的详细内容 git show dfb02 # 可只用 commitid 的前几位 git show HEAD # 显示 HEAD 提交日志 git show v2.0 # 显示 v2.0 的日志及详细内容 git show HEAD^ # 显示 HEAD 的父（上一个版本）的提交日志 ^^ 为上两个版本 ^5 为上 5 个版本 git show-branch # 图示当前分支历史 git show-branch --all # 图示所有分支历史 git show HEAD~3git show -s --pretty=raw 2be7fcb476git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示 master 分支昨天的状态 4. git diff 123456git diff # 显示所有未添加至 index 的变更 git diff --cached # 显示所有已添加 index 但还未 commit 的变更 git diff HEAD^ # 比较与上一个版本的差异 git diff HEAD -- ./lib # 比较与 HEAD 版本 lib 目录的差异 git diff origin/master..master # 比较远程分支 master 上有本地分支 master 上没有的 git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容 4.1. git branch 123456789git branch # 显示本地分支 git branch --contains 50089 # 显示包含提交 50089 的分支 git branch -a # 显示所有分支 git branch -r # 显示所有原创分支 git branch --merged # 显示所有已合并到当前分支的分支 git branch --no-merged # 显示所有未合并到当前分支的分支 git branch -m master master_copy # 本地分支改名 git branch -d hotfixes/BJVEP933 # 删除分支 hotfixes/BJVEP933（本分支修改已合并到其他分支）git branch -D hotfixes/BJVEP933 # 强制删除分支 hotfixes/BJVEP933 4.2. git checkout 12345678git checkout abcde file/to/restore # 单一文件回退到某个版本 git checkout -b master_copy # 从当前分支创建新分支 master_copy 并检出 git checkout -b master master_copy # 上面的完整版 git checkout features/performance # 检出已存在的 features/performance 分支 git checkout --track hotfixes/BJVEP933 # 检出远程分支 hotfixes/BJVEP933 并创建本地跟踪分支 git checkout v2.0 # 检出版本 v2.0git checkout -b devel origin/develop # 从远程分支 develop 创建新本地分支 devel 并检出 git checkout -- README # 检出 head 版本的 README 文件（可用于修改错误回退） 4.3. git fetch 12345git fetch # 获取所有远程分支（不更新本地分支，另需 merge）git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支 git fetch --all # 1. 获取所有远程分支 git reset --hard origin/master # 2. 先运行 1，再使用远程文件 &lt;b&gt; 强制覆盖 &lt;/b&gt; 本地文件 git reset --hard HEAD # 将当前版本重置为 HEAD（通常用于 merge 失败回退） 4.4. git tag 12345678910111213141516git tag # git 列表 git tag v0.1.1 # 打标签 git tag v0.1.1 6224937 # 补打标签 git tag v0.1.2-light # 创建轻量标签 - 轻量标签是指向提交对象的引用 (暂时没用到)git tag -a v0.1.2 -m "0.1.2 版本备注" # 附注标签则是仓库中的一个独立对象。建议使用附注标签 git tag -a v0.1.1 9fbc3d0 # 给指定的 commit 打标签（即补打标签）git checkou [tagname] # 切换标签 git tag -d v0.1.2 # 删除标签 git push origin :refs/tags/v0.9 # 删除远程标签 (需要先删除本地标签)git push origin v0.1.2 # 提交单一标签 git push origin --tags # 提交所有标签 git show v1.2.5 # 查看标签内容 git tag -l | xargs git tag -d # Delete local tags.git fetch # Fetch remote tags.git tag -l | xargs -n 1 git push --delete origin # Delete remote tags.git tag -l | xargs git tag -d # Delete local tasg. 4.5. 其它命令 12345678git merge origin/master # 合并远程 master 分支至当前分支 git cherry-pick ff44785404a8e # 合并提交 ff44785404a8e 的修改 git push origin master # 将当前分支 push 到远程 master 分支 git push origin :hotfixes/BJVEP933 # 删除远程仓库的 hotfixes/BJVEP933 分支 git push --tags # 把所有 tag 推送到远程仓库 git pull origin master # 获取远程分支 master 并 merge 到当前分支 git mv README README2 # 重命名文件 README 为 README2git rebase]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
